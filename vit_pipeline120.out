/home/kl321/AutoSAM/scripts/main_autosam_seg.py:116: UserWarning: You have chosen a specific GPU. This will completely disable data parallelism.
  warnings.warn('You have chosen a specific GPU. This will completely '
Use GPU: 0 for training
loaded keys: dict_keys(['image_encoder.neck.0.weight', 'image_encoder.neck.1.weight', 'image_encoder.neck.1.bias', 'image_encoder.neck.2.weight', 'image_encoder.neck.3.weight', 'image_encoder.neck.3.bias', 'image_encoder.patch_embed.proj.weight', 'image_encoder.patch_embed.proj.bias', 'image_encoder.blocks.0.norm1.weight', 'image_encoder.blocks.0.norm1.bias', 'image_encoder.blocks.0.attn.rel_pos_h', 'image_encoder.blocks.0.attn.rel_pos_w', 'image_encoder.blocks.0.attn.qkv.weight', 'image_encoder.blocks.0.attn.qkv.bias', 'image_encoder.blocks.0.attn.proj.weight', 'image_encoder.blocks.0.attn.proj.bias', 'image_encoder.blocks.0.norm2.weight', 'image_encoder.blocks.0.norm2.bias', 'image_encoder.blocks.0.mlp.lin1.weight', 'image_encoder.blocks.0.mlp.lin1.bias', 'image_encoder.blocks.0.mlp.lin2.weight', 'image_encoder.blocks.0.mlp.lin2.bias', 'image_encoder.blocks.1.norm1.weight', 'image_encoder.blocks.1.norm1.bias', 'image_encoder.blocks.1.attn.rel_pos_h', 'image_encoder.blocks.1.attn.rel_pos_w', 'image_encoder.blocks.1.attn.qkv.weight', 'image_encoder.blocks.1.attn.qkv.bias', 'image_encoder.blocks.1.attn.proj.weight', 'image_encoder.blocks.1.attn.proj.bias', 'image_encoder.blocks.1.norm2.weight', 'image_encoder.blocks.1.norm2.bias', 'image_encoder.blocks.1.mlp.lin1.weight', 'image_encoder.blocks.1.mlp.lin1.bias', 'image_encoder.blocks.1.mlp.lin2.weight', 'image_encoder.blocks.1.mlp.lin2.bias', 'image_encoder.blocks.2.norm1.weight', 'image_encoder.blocks.2.norm1.bias', 'image_encoder.blocks.2.attn.rel_pos_h', 'image_encoder.blocks.2.attn.rel_pos_w', 'image_encoder.blocks.2.attn.qkv.weight', 'image_encoder.blocks.2.attn.qkv.bias', 'image_encoder.blocks.2.attn.proj.weight', 'image_encoder.blocks.2.attn.proj.bias', 'image_encoder.blocks.2.norm2.weight', 'image_encoder.blocks.2.norm2.bias', 'image_encoder.blocks.2.mlp.lin1.weight', 'image_encoder.blocks.2.mlp.lin1.bias', 'image_encoder.blocks.2.mlp.lin2.weight', 'image_encoder.blocks.2.mlp.lin2.bias', 'image_encoder.blocks.3.norm1.weight', 'image_encoder.blocks.3.norm1.bias', 'image_encoder.blocks.3.attn.rel_pos_h', 'image_encoder.blocks.3.attn.rel_pos_w', 'image_encoder.blocks.3.attn.qkv.weight', 'image_encoder.blocks.3.attn.qkv.bias', 'image_encoder.blocks.3.attn.proj.weight', 'image_encoder.blocks.3.attn.proj.bias', 'image_encoder.blocks.3.norm2.weight', 'image_encoder.blocks.3.norm2.bias', 'image_encoder.blocks.3.mlp.lin1.weight', 'image_encoder.blocks.3.mlp.lin1.bias', 'image_encoder.blocks.3.mlp.lin2.weight', 'image_encoder.blocks.3.mlp.lin2.bias', 'image_encoder.blocks.4.norm1.weight', 'image_encoder.blocks.4.norm1.bias', 'image_encoder.blocks.4.attn.rel_pos_h', 'image_encoder.blocks.4.attn.rel_pos_w', 'image_encoder.blocks.4.attn.qkv.weight', 'image_encoder.blocks.4.attn.qkv.bias', 'image_encoder.blocks.4.attn.proj.weight', 'image_encoder.blocks.4.attn.proj.bias', 'image_encoder.blocks.4.norm2.weight', 'image_encoder.blocks.4.norm2.bias', 'image_encoder.blocks.4.mlp.lin1.weight', 'image_encoder.blocks.4.mlp.lin1.bias', 'image_encoder.blocks.4.mlp.lin2.weight', 'image_encoder.blocks.4.mlp.lin2.bias', 'image_encoder.blocks.5.norm1.weight', 'image_encoder.blocks.5.norm1.bias', 'image_encoder.blocks.5.attn.rel_pos_h', 'image_encoder.blocks.5.attn.rel_pos_w', 'image_encoder.blocks.5.attn.qkv.weight', 'image_encoder.blocks.5.attn.qkv.bias', 'image_encoder.blocks.5.attn.proj.weight', 'image_encoder.blocks.5.attn.proj.bias', 'image_encoder.blocks.5.norm2.weight', 'image_encoder.blocks.5.norm2.bias', 'image_encoder.blocks.5.mlp.lin1.weight', 'image_encoder.blocks.5.mlp.lin1.bias', 'image_encoder.blocks.5.mlp.lin2.weight', 'image_encoder.blocks.5.mlp.lin2.bias', 'image_encoder.blocks.6.norm1.weight', 'image_encoder.blocks.6.norm1.bias', 'image_encoder.blocks.6.attn.rel_pos_h', 'image_encoder.blocks.6.attn.rel_pos_w', 'image_encoder.blocks.6.attn.qkv.weight', 'image_encoder.blocks.6.attn.qkv.bias', 'image_encoder.blocks.6.attn.proj.weight', 'image_encoder.blocks.6.attn.proj.bias', 'image_encoder.blocks.6.norm2.weight', 'image_encoder.blocks.6.norm2.bias', 'image_encoder.blocks.6.mlp.lin1.weight', 'image_encoder.blocks.6.mlp.lin1.bias', 'image_encoder.blocks.6.mlp.lin2.weight', 'image_encoder.blocks.6.mlp.lin2.bias', 'image_encoder.blocks.7.norm1.weight', 'image_encoder.blocks.7.norm1.bias', 'image_encoder.blocks.7.attn.rel_pos_h', 'image_encoder.blocks.7.attn.rel_pos_w', 'image_encoder.blocks.7.attn.qkv.weight', 'image_encoder.blocks.7.attn.qkv.bias', 'image_encoder.blocks.7.attn.proj.weight', 'image_encoder.blocks.7.attn.proj.bias', 'image_encoder.blocks.7.norm2.weight', 'image_encoder.blocks.7.norm2.bias', 'image_encoder.blocks.7.mlp.lin1.weight', 'image_encoder.blocks.7.mlp.lin1.bias', 'image_encoder.blocks.7.mlp.lin2.weight', 'image_encoder.blocks.7.mlp.lin2.bias', 'image_encoder.blocks.8.norm1.weight', 'image_encoder.blocks.8.norm1.bias', 'image_encoder.blocks.8.attn.rel_pos_h', 'image_encoder.blocks.8.attn.rel_pos_w', 'image_encoder.blocks.8.attn.qkv.weight', 'image_encoder.blocks.8.attn.qkv.bias', 'image_encoder.blocks.8.attn.proj.weight', 'image_encoder.blocks.8.attn.proj.bias', 'image_encoder.blocks.8.norm2.weight', 'image_encoder.blocks.8.norm2.bias', 'image_encoder.blocks.8.mlp.lin1.weight', 'image_encoder.blocks.8.mlp.lin1.bias', 'image_encoder.blocks.8.mlp.lin2.weight', 'image_encoder.blocks.8.mlp.lin2.bias', 'image_encoder.blocks.9.norm1.weight', 'image_encoder.blocks.9.norm1.bias', 'image_encoder.blocks.9.attn.rel_pos_h', 'image_encoder.blocks.9.attn.rel_pos_w', 'image_encoder.blocks.9.attn.qkv.weight', 'image_encoder.blocks.9.attn.qkv.bias', 'image_encoder.blocks.9.attn.proj.weight', 'image_encoder.blocks.9.attn.proj.bias', 'image_encoder.blocks.9.norm2.weight', 'image_encoder.blocks.9.norm2.bias', 'image_encoder.blocks.9.mlp.lin1.weight', 'image_encoder.blocks.9.mlp.lin1.bias', 'image_encoder.blocks.9.mlp.lin2.weight', 'image_encoder.blocks.9.mlp.lin2.bias', 'image_encoder.blocks.10.norm1.weight', 'image_encoder.blocks.10.norm1.bias', 'image_encoder.blocks.10.attn.rel_pos_h', 'image_encoder.blocks.10.attn.rel_pos_w', 'image_encoder.blocks.10.attn.qkv.weight', 'image_encoder.blocks.10.attn.qkv.bias', 'image_encoder.blocks.10.attn.proj.weight', 'image_encoder.blocks.10.attn.proj.bias', 'image_encoder.blocks.10.norm2.weight', 'image_encoder.blocks.10.norm2.bias', 'image_encoder.blocks.10.mlp.lin1.weight', 'image_encoder.blocks.10.mlp.lin1.bias', 'image_encoder.blocks.10.mlp.lin2.weight', 'image_encoder.blocks.10.mlp.lin2.bias', 'image_encoder.blocks.11.norm1.weight', 'image_encoder.blocks.11.norm1.bias', 'image_encoder.blocks.11.attn.rel_pos_h', 'image_encoder.blocks.11.attn.rel_pos_w', 'image_encoder.blocks.11.attn.qkv.weight', 'image_encoder.blocks.11.attn.qkv.bias', 'image_encoder.blocks.11.attn.proj.weight', 'image_encoder.blocks.11.attn.proj.bias', 'image_encoder.blocks.11.norm2.weight', 'image_encoder.blocks.11.norm2.bias', 'image_encoder.blocks.11.mlp.lin1.weight', 'image_encoder.blocks.11.mlp.lin1.bias', 'image_encoder.blocks.11.mlp.lin2.weight', 'image_encoder.blocks.11.mlp.lin2.bias', 'mask_decoder.transformer.layers.0.self_attn.q_proj.weight', 'mask_decoder.transformer.layers.0.self_attn.q_proj.bias', 'mask_decoder.transformer.layers.0.self_attn.k_proj.weight', 'mask_decoder.transformer.layers.0.self_attn.k_proj.bias', 'mask_decoder.transformer.layers.0.self_attn.v_proj.weight', 'mask_decoder.transformer.layers.0.self_attn.v_proj.bias', 'mask_decoder.transformer.layers.0.self_attn.out_proj.weight', 'mask_decoder.transformer.layers.0.self_attn.out_proj.bias', 'mask_decoder.transformer.layers.0.norm1.weight', 'mask_decoder.transformer.layers.0.norm1.bias', 'mask_decoder.transformer.layers.0.cross_attn_token_to_image.q_proj.weight', 'mask_decoder.transformer.layers.0.cross_attn_token_to_image.q_proj.bias', 'mask_decoder.transformer.layers.0.cross_attn_token_to_image.k_proj.weight', 'mask_decoder.transformer.layers.0.cross_attn_token_to_image.k_proj.bias', 'mask_decoder.transformer.layers.0.cross_attn_token_to_image.v_proj.weight', 'mask_decoder.transformer.layers.0.cross_attn_token_to_image.v_proj.bias', 'mask_decoder.transformer.layers.0.cross_attn_token_to_image.out_proj.weight', 'mask_decoder.transformer.layers.0.cross_attn_token_to_image.out_proj.bias', 'mask_decoder.transformer.layers.0.norm2.weight', 'mask_decoder.transformer.layers.0.norm2.bias', 'mask_decoder.transformer.layers.0.mlp.lin1.weight', 'mask_decoder.transformer.layers.0.mlp.lin1.bias', 'mask_decoder.transformer.layers.0.mlp.lin2.weight', 'mask_decoder.transformer.layers.0.mlp.lin2.bias', 'mask_decoder.transformer.layers.0.norm3.weight', 'mask_decoder.transformer.layers.0.norm3.bias', 'mask_decoder.transformer.layers.0.norm4.weight', 'mask_decoder.transformer.layers.0.norm4.bias', 'mask_decoder.transformer.layers.0.cross_attn_image_to_token.q_proj.weight', 'mask_decoder.transformer.layers.0.cross_attn_image_to_token.q_proj.bias', 'mask_decoder.transformer.layers.0.cross_attn_image_to_token.k_proj.weight', 'mask_decoder.transformer.layers.0.cross_attn_image_to_token.k_proj.bias', 'mask_decoder.transformer.layers.0.cross_attn_image_to_token.v_proj.weight', 'mask_decoder.transformer.layers.0.cross_attn_image_to_token.v_proj.bias', 'mask_decoder.transformer.layers.0.cross_attn_image_to_token.out_proj.weight', 'mask_decoder.transformer.layers.0.cross_attn_image_to_token.out_proj.bias', 'mask_decoder.transformer.layers.1.self_attn.q_proj.weight', 'mask_decoder.transformer.layers.1.self_attn.q_proj.bias', 'mask_decoder.transformer.layers.1.self_attn.k_proj.weight', 'mask_decoder.transformer.layers.1.self_attn.k_proj.bias', 'mask_decoder.transformer.layers.1.self_attn.v_proj.weight', 'mask_decoder.transformer.layers.1.self_attn.v_proj.bias', 'mask_decoder.transformer.layers.1.self_attn.out_proj.weight', 'mask_decoder.transformer.layers.1.self_attn.out_proj.bias', 'mask_decoder.transformer.layers.1.norm1.weight', 'mask_decoder.transformer.layers.1.norm1.bias', 'mask_decoder.transformer.layers.1.cross_attn_token_to_image.q_proj.weight', 'mask_decoder.transformer.layers.1.cross_attn_token_to_image.q_proj.bias', 'mask_decoder.transformer.layers.1.cross_attn_token_to_image.k_proj.weight', 'mask_decoder.transformer.layers.1.cross_attn_token_to_image.k_proj.bias', 'mask_decoder.transformer.layers.1.cross_attn_token_to_image.v_proj.weight', 'mask_decoder.transformer.layers.1.cross_attn_token_to_image.v_proj.bias', 'mask_decoder.transformer.layers.1.cross_attn_token_to_image.out_proj.weight', 'mask_decoder.transformer.layers.1.cross_attn_token_to_image.out_proj.bias', 'mask_decoder.transformer.layers.1.norm2.weight', 'mask_decoder.transformer.layers.1.norm2.bias', 'mask_decoder.transformer.layers.1.mlp.lin1.weight', 'mask_decoder.transformer.layers.1.mlp.lin1.bias', 'mask_decoder.transformer.layers.1.mlp.lin2.weight', 'mask_decoder.transformer.layers.1.mlp.lin2.bias', 'mask_decoder.transformer.layers.1.norm3.weight', 'mask_decoder.transformer.layers.1.norm3.bias', 'mask_decoder.transformer.layers.1.norm4.weight', 'mask_decoder.transformer.layers.1.norm4.bias', 'mask_decoder.transformer.layers.1.cross_attn_image_to_token.q_proj.weight', 'mask_decoder.transformer.layers.1.cross_attn_image_to_token.q_proj.bias', 'mask_decoder.transformer.layers.1.cross_attn_image_to_token.k_proj.weight', 'mask_decoder.transformer.layers.1.cross_attn_image_to_token.k_proj.bias', 'mask_decoder.transformer.layers.1.cross_attn_image_to_token.v_proj.weight', 'mask_decoder.transformer.layers.1.cross_attn_image_to_token.v_proj.bias', 'mask_decoder.transformer.layers.1.cross_attn_image_to_token.out_proj.weight', 'mask_decoder.transformer.layers.1.cross_attn_image_to_token.out_proj.bias', 'mask_decoder.transformer.final_attn_token_to_image.q_proj.weight', 'mask_decoder.transformer.final_attn_token_to_image.q_proj.bias', 'mask_decoder.transformer.final_attn_token_to_image.k_proj.weight', 'mask_decoder.transformer.final_attn_token_to_image.k_proj.bias', 'mask_decoder.transformer.final_attn_token_to_image.v_proj.weight', 'mask_decoder.transformer.final_attn_token_to_image.v_proj.bias', 'mask_decoder.transformer.final_attn_token_to_image.out_proj.weight', 'mask_decoder.transformer.final_attn_token_to_image.out_proj.bias', 'mask_decoder.transformer.norm_final_attn.weight', 'mask_decoder.transformer.norm_final_attn.bias', 'mask_decoder.output_upscaling.0.weight', 'mask_decoder.output_upscaling.0.bias', 'mask_decoder.output_upscaling.1.weight', 'mask_decoder.output_upscaling.1.bias', 'mask_decoder.output_upscaling.3.weight', 'mask_decoder.output_upscaling.3.bias', 'mask_decoder.output_hypernetworks_mlps.0.layers.0.weight', 'mask_decoder.output_hypernetworks_mlps.0.layers.0.bias', 'mask_decoder.output_hypernetworks_mlps.0.layers.1.weight', 'mask_decoder.output_hypernetworks_mlps.0.layers.1.bias', 'mask_decoder.output_hypernetworks_mlps.0.layers.2.weight', 'mask_decoder.output_hypernetworks_mlps.0.layers.2.bias', 'mask_decoder.output_hypernetworks_mlps.1.layers.0.weight', 'mask_decoder.output_hypernetworks_mlps.1.layers.0.bias', 'mask_decoder.output_hypernetworks_mlps.1.layers.1.weight', 'mask_decoder.output_hypernetworks_mlps.1.layers.1.bias', 'mask_decoder.output_hypernetworks_mlps.1.layers.2.weight', 'mask_decoder.output_hypernetworks_mlps.1.layers.2.bias', 'image_encoder.pos_embed'])
['patient_035']
['patient_057', 'patient_028', 'patient_087', 'patient_061', 'patient_032', 'patient_011', 'patient_078', 'patient_009', 'patient_068', 'patient_021', 'patient_079', 'patient_004', 'patient_089', 'patient_023', 'patient_070']
['patient_014', 'patient_060', 'patient_044', 'patient_036', 'patient_003', 'patient_100', 'patient_065', 'patient_013', 'patient_038', 'patient_093', 'patient_043', 'patient_082', 'patient_031', 'patient_005', 'patient_016']
dataset length: 26
dataset length: 258
dataset length: 296
output_experiment/vit120
Train: [0][0/7]	loss 4.5290
Validating: Epoch:  0 Loss: 0.9574 IoU_pred: -0.1887
Train: [1][0/7]	loss 1.0845
Validating: Epoch:  1 Loss: 0.8133 IoU_pred: -0.1996
Train: [2][0/7]	loss 1.0807
Validating: Epoch:  2 Loss: 0.7201 IoU_pred: -0.1864
Train: [3][0/7]	loss 0.6532
Validating: Epoch:  3 Loss: 0.6273 IoU_pred: -0.1548
Train: [4][0/7]	loss 0.7160
Validating: Epoch:  4 Loss: 0.6000 IoU_pred: -0.1910
Train: [5][0/7]	loss 1.4021
Validating: Epoch:  5 Loss: 0.5261 IoU_pred: -0.1848
Train: [6][0/7]	loss 0.3119
Validating: Epoch:  6 Loss: 0.5342 IoU_pred: -0.1751
Train: [7][0/7]	loss 0.6007
Validating: Epoch:  7 Loss: 0.5631 IoU_pred: -0.1642
Train: [8][0/7]	loss 0.5501
Validating: Epoch:  8 Loss: 0.5484 IoU_pred: -0.1661
Train: [9][0/7]	loss 0.3977
Validating: Epoch:  9 Loss: 0.5698 IoU_pred: -0.1582
Train: [10][0/7]	loss 0.6723
Validating: Epoch: 10 Loss: 0.5290 IoU_pred: -0.1643
Train: [11][0/7]	loss 0.7927
Validating: Epoch: 11 Loss: 0.5241 IoU_pred: -0.1982
Train: [12][0/7]	loss 0.9643
Validating: Epoch: 12 Loss: 0.4784 IoU_pred: -0.1972
Train: [13][0/7]	loss 0.3852
Validating: Epoch: 13 Loss: 0.5088 IoU_pred: -0.2037
Train: [14][0/7]	loss 0.3222
Validating: Epoch: 14 Loss: 0.5035 IoU_pred: -0.1920
Train: [15][0/7]	loss 0.6058
Validating: Epoch: 15 Loss: 0.5384 IoU_pred: -0.1920
Train: [16][0/7]	loss 0.3943
Validating: Epoch: 16 Loss: 0.5052 IoU_pred: -0.1911
Train: [17][0/7]	loss 0.6103
Validating: Epoch: 17 Loss: 0.4769 IoU_pred: -0.2110
Train: [18][0/7]	loss 0.5240
Validating: Epoch: 18 Loss: 0.4548 IoU_pred: -0.1749
Train: [19][0/7]	loss 0.3387
Validating: Epoch: 19 Loss: 0.4801 IoU_pred: -0.1800
Train: [20][0/7]	loss 0.4869
Validating: Epoch: 20 Loss: 0.4773 IoU_pred: -0.1731
Train: [21][0/7]	loss 0.2733
Validating: Epoch: 21 Loss: 0.4732 IoU_pred: -0.1657
Train: [22][0/7]	loss 0.3507
Validating: Epoch: 22 Loss: 0.4600 IoU_pred: -0.2003
Train: [23][0/7]	loss 0.4700
Validating: Epoch: 23 Loss: 0.4646 IoU_pred: -0.1909
Train: [24][0/7]	loss 0.3760
Validating: Epoch: 24 Loss: 0.5507 IoU_pred: -0.1839
Train: [25][0/7]	loss 0.3592
Validating: Epoch: 25 Loss: 0.5522 IoU_pred: -0.1766
Train: [26][0/7]	loss 0.3280
Validating: Epoch: 26 Loss: 0.4629 IoU_pred: -0.1235
Train: [27][0/7]	loss 0.6334
Validating: Epoch: 27 Loss: 0.4532 IoU_pred: -0.1175
Train: [28][0/7]	loss 0.5429
Validating: Epoch: 28 Loss: 0.4402 IoU_pred: -0.1419
Train: [29][0/7]	loss 0.4446
Validating: Epoch: 29 Loss: 0.4344 IoU_pred: -0.1333
Train: [30][0/7]	loss 0.3515
Validating: Epoch: 30 Loss: 0.4475 IoU_pred: -0.1145
Train: [31][0/7]	loss 0.4093
Validating: Epoch: 31 Loss: 0.4570 IoU_pred: -0.1083
Train: [32][0/7]	loss 0.5241
Validating: Epoch: 32 Loss: 0.4433 IoU_pred: -0.1530
Train: [33][0/7]	loss 0.2306
Validating: Epoch: 33 Loss: 0.4466 IoU_pred: -0.1246
Train: [34][0/7]	loss 0.4172
Validating: Epoch: 34 Loss: 0.4150 IoU_pred: -0.1147
Train: [35][0/7]	loss 0.2342
Validating: Epoch: 35 Loss: 0.4238 IoU_pred: -0.1171
Train: [36][0/7]	loss 0.4542
Validating: Epoch: 36 Loss: 0.4253 IoU_pred: -0.1429
Train: [37][0/7]	loss 0.4916
Validating: Epoch: 37 Loss: 0.4809 IoU_pred: -0.1538
Train: [38][0/7]	loss 0.4496
Validating: Epoch: 38 Loss: 0.4450 IoU_pred: -0.1056
Train: [39][0/7]	loss 0.3673
Validating: Epoch: 39 Loss: 0.4335 IoU_pred: -0.1351
Train: [40][0/7]	loss 0.2733
Validating: Epoch: 40 Loss: 0.4679 IoU_pred: -0.1260
Train: [41][0/7]	loss 0.3600
Validating: Epoch: 41 Loss: 0.4041 IoU_pred: -0.1410
Train: [42][0/7]	loss 0.7002
Validating: Epoch: 42 Loss: 0.4045 IoU_pred: -0.1219
Train: [43][0/7]	loss 0.4634
Validating: Epoch: 43 Loss: 0.4452 IoU_pred: -0.1104
Train: [44][0/7]	loss 0.3948
Validating: Epoch: 44 Loss: 0.4930 IoU_pred: -0.0979
Train: [45][0/7]	loss 0.2452
Validating: Epoch: 45 Loss: 0.4396 IoU_pred: -0.0851
Train: [46][0/7]	loss 0.5324
Validating: Epoch: 46 Loss: 0.4282 IoU_pred: -0.0754
Train: [47][0/7]	loss 0.3528
Validating: Epoch: 47 Loss: 0.4323 IoU_pred: -0.0885
Train: [48][0/7]	loss 0.2431
Validating: Epoch: 48 Loss: 0.4534 IoU_pred: -0.0964
Train: [49][0/7]	loss 0.1224
Validating: Epoch: 49 Loss: 0.4571 IoU_pred: -0.0954
Train: [50][0/7]	loss 0.2331
Validating: Epoch: 50 Loss: 0.4615 IoU_pred: -0.1004
Train: [51][0/7]	loss 0.3012
Validating: Epoch: 51 Loss: 0.4366 IoU_pred: -0.0871
Train: [52][0/7]	loss 0.6048
Validating: Epoch: 52 Loss: 0.4238 IoU_pred: -0.0752
Train: [53][0/7]	loss 0.3228
Validating: Epoch: 53 Loss: 0.4415 IoU_pred: -0.0883
Train: [54][0/7]	loss 0.3866
Validating: Epoch: 54 Loss: 0.4589 IoU_pred: -0.1043
Train: [55][0/7]	loss 0.2762
Validating: Epoch: 55 Loss: 0.4389 IoU_pred: -0.0810
Train: [56][0/7]	loss 0.1451
Validating: Epoch: 56 Loss: 0.4503 IoU_pred: -0.0830
Train: [57][0/7]	loss 0.2334
Validating: Epoch: 57 Loss: 0.4409 IoU_pred: -0.0919
Train: [58][0/7]	loss 0.3720
Validating: Epoch: 58 Loss: 0.4468 IoU_pred: -0.0963
Train: [59][0/7]	loss 0.3304
Validating: Epoch: 59 Loss: 0.4363 IoU_pred: -0.1002
Train: [60][0/7]	loss 0.1629
Validating: Epoch: 60 Loss: 0.4452 IoU_pred: -0.1026
Train: [61][0/7]	loss 0.4115
Validating: Epoch: 61 Loss: 0.4444 IoU_pred: -0.1011
Train: [62][0/7]	loss 0.1485
Validating: Epoch: 62 Loss: 0.4402 IoU_pred: -0.0946
Train: [63][0/7]	loss 0.1819
Validating: Epoch: 63 Loss: 0.4265 IoU_pred: -0.0989
Train: [64][0/7]	loss 0.3768
Validating: Epoch: 64 Loss: 0.4238 IoU_pred: -0.1017
Train: [65][0/7]	loss 0.3706
Validating: Epoch: 65 Loss: 0.4335 IoU_pred: -0.1032
Train: [66][0/7]	loss 0.2701
Validating: Epoch: 66 Loss: 0.4372 IoU_pred: -0.1014
Train: [67][0/7]	loss 0.2489
Validating: Epoch: 67 Loss: 0.4426 IoU_pred: -0.0883
Train: [68][0/7]	loss 0.1479
Validating: Epoch: 68 Loss: 0.4496 IoU_pred: -0.0897
Train: [69][0/7]	loss 0.2238
Validating: Epoch: 69 Loss: 0.4410 IoU_pred: -0.0856
Train: [70][0/7]	loss 0.3652
Validating: Epoch: 70 Loss: 0.4427 IoU_pred: -0.0924
Train: [71][0/7]	loss 0.4723
Validating: Epoch: 71 Loss: 0.4351 IoU_pred: -0.0772
Train: [72][0/7]	loss 0.1209
Validating: Epoch: 72 Loss: 0.4204 IoU_pred: -0.0740
Train: [73][0/7]	loss 0.2020
Validating: Epoch: 73 Loss: 0.4407 IoU_pred: -0.0998
Train: [74][0/7]	loss 0.2795
Validating: Epoch: 74 Loss: 0.4514 IoU_pred: -0.0757
Train: [75][0/7]	loss 0.4403
Validating: Epoch: 75 Loss: 0.4274 IoU_pred: -0.0972
Train: [76][0/7]	loss 0.1922
Validating: Epoch: 76 Loss: 0.4266 IoU_pred: -0.0847
Train: [77][0/7]	loss 0.3561
Validating: Epoch: 77 Loss: 0.4224 IoU_pred: -0.0849
Train: [78][0/7]	loss 0.1888
Validating: Epoch: 78 Loss: 0.4256 IoU_pred: -0.0925
Train: [79][0/7]	loss 0.4729
Validating: Epoch: 79 Loss: 0.4315 IoU_pred: -0.0830
Train: [80][0/7]	loss 0.2547
Validating: Epoch: 80 Loss: 0.4264 IoU_pred: -0.0715
Train: [81][0/7]	loss 0.2290
Validating: Epoch: 81 Loss: 0.4320 IoU_pred: -0.0882
Train: [82][0/7]	loss 0.4240
Validating: Epoch: 82 Loss: 0.4283 IoU_pred: -0.0799
Train: [83][0/7]	loss 0.1606
Validating: Epoch: 83 Loss: 0.4299 IoU_pred: -0.0817
Train: [84][0/7]	loss 0.2197
Validating: Epoch: 84 Loss: 0.4357 IoU_pred: -0.0810
Train: [85][0/7]	loss 0.2041
Validating: Epoch: 85 Loss: 0.4298 IoU_pred: -0.0853
Train: [86][0/7]	loss 0.3487
Validating: Epoch: 86 Loss: 0.4259 IoU_pred: -0.0842
Train: [87][0/7]	loss 0.1601
Validating: Epoch: 87 Loss: 0.4230 IoU_pred: -0.0819
Train: [88][0/7]	loss 0.0753
Validating: Epoch: 88 Loss: 0.4200 IoU_pred: -0.0815
Train: [89][0/7]	loss 0.2046
Validating: Epoch: 89 Loss: 0.4176 IoU_pred: -0.0869
Train: [90][0/7]	loss 0.7202
Validating: Epoch: 90 Loss: 0.4212 IoU_pred: -0.0683
Train: [91][0/7]	loss 0.5404
Validating: Epoch: 91 Loss: 0.4234 IoU_pred: -0.0999
Train: [92][0/7]	loss 0.1518
Validating: Epoch: 92 Loss: 0.4267 IoU_pred: -0.0866
Train: [93][0/7]	loss 0.1271
Validating: Epoch: 93 Loss: 0.4228 IoU_pred: -0.0908
Train: [94][0/7]	loss 0.4773
Validating: Epoch: 94 Loss: 0.4310 IoU_pred: -0.0818
Train: [95][0/7]	loss 0.7911
Validating: Epoch: 95 Loss: 0.4246 IoU_pred: -0.0797
Train: [96][0/7]	loss 0.2204
Validating: Epoch: 96 Loss: 0.4258 IoU_pred: -0.0772
Train: [97][0/7]	loss 0.2229
Validating: Epoch: 97 Loss: 0.4301 IoU_pred: -0.0967
Train: [98][0/7]	loss 0.2015
Validating: Epoch: 98 Loss: 0.4313 IoU_pred: -0.0993
Train: [99][0/7]	loss 0.2393
Validating: Epoch: 99 Loss: 0.4307 IoU_pred: -0.0760
Train: [100][0/7]	loss 0.1580
Validating: Epoch: 100 Loss: 0.4156 IoU_pred: -0.0895
Train: [101][0/7]	loss 0.2227
Validating: Epoch: 101 Loss: 0.4363 IoU_pred: -0.0835
Train: [102][0/7]	loss 0.2394
Validating: Epoch: 102 Loss: 0.4262 IoU_pred: -0.1108
Train: [103][0/7]	loss 0.1809
Validating: Epoch: 103 Loss: 0.4233 IoU_pred: -0.0904
Train: [104][0/7]	loss 0.5347
Validating: Epoch: 104 Loss: 0.4317 IoU_pred: -0.0837
Train: [105][0/7]	loss 0.2918
Validating: Epoch: 105 Loss: 0.4224 IoU_pred: -0.0736
Train: [106][0/7]	loss 0.1084
Validating: Epoch: 106 Loss: 0.4193 IoU_pred: -0.0872
Train: [107][0/7]	loss 0.1836
Validating: Epoch: 107 Loss: 0.4358 IoU_pred: -0.0727
Train: [108][0/7]	loss 0.1634
Validating: Epoch: 108 Loss: 0.4286 IoU_pred: -0.0696
Train: [109][0/7]	loss 0.2332
Validating: Epoch: 109 Loss: 0.4298 IoU_pred: -0.0840
Train: [110][0/7]	loss 0.2598
Validating: Epoch: 110 Loss: 0.4302 IoU_pred: -0.0699
Train: [111][0/7]	loss 0.3472
Validating: Epoch: 111 Loss: 0.4192 IoU_pred: -0.0863
Train: [112][0/7]	loss 0.2622
Validating: Epoch: 112 Loss: 0.4213 IoU_pred: -0.0950
Train: [113][0/7]	loss 0.2132
Validating: Epoch: 113 Loss: 0.4342 IoU_pred: -0.0785
Train: [114][0/7]	loss 0.3220
Validating: Epoch: 114 Loss: 0.4267 IoU_pred: -0.0723
Train: [115][0/7]	loss 0.3333
Validating: Epoch: 115 Loss: 0.4239 IoU_pred: -0.0820
Train: [116][0/7]	loss 0.0952
Validating: Epoch: 116 Loss: 0.4272 IoU_pred: -0.0676
Train: [117][0/7]	loss 0.5089
Validating: Epoch: 117 Loss: 0.4370 IoU_pred: -0.0740
Train: [118][0/7]	loss 0.2885
Validating: Epoch: 118 Loss: 0.4282 IoU_pred: -0.0776
Train: [119][0/7]	loss 0.1443
Validating: Epoch: 119 Loss: 0.4220 IoU_pred: -0.0731
Test
dataset length: 20
(20, 224, 224) (20, 224, 224)
finish saving file: patient_014
dataset length: 18
(18, 224, 224) (18, 224, 224)
finish saving file: patient_060
dataset length: 18
(18, 224, 224) (18, 224, 224)
finish saving file: patient_044
dataset length: 16
(16, 224, 224) (16, 224, 224)
finish saving file: patient_036
dataset length: 20
(20, 224, 224) (20, 224, 224)
finish saving file: patient_003
dataset length: 16
(16, 224, 224) (16, 224, 224)
finish saving file: patient_100
dataset length: 16
(16, 224, 224) (16, 224, 224)
finish saving file: patient_065
dataset length: 20
(20, 224, 224) (20, 224, 224)
finish saving file: patient_013
dataset length: 16
(16, 224, 224) (16, 224, 224)
finish saving file: patient_038
dataset length: 20
(20, 224, 224) (20, 224, 224)
finish saving file: patient_093
dataset length: 24
(24, 224, 224) (24, 224, 224)
finish saving file: patient_043
dataset length: 32
(32, 224, 224) (32, 224, 224)
finish saving file: patient_082
dataset length: 20
(20, 224, 224) (20, 224, 224)
finish saving file: patient_031
dataset length: 20
(20, 224, 224) (20, 224, 224)
finish saving file: patient_005
dataset length: 20
/home/kl321/miniconda3/envs/medsam/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.
  return _methods._mean(a, axis=axis, dtype=dtype,
/home/kl321/miniconda3/envs/medsam/lib/python3.10/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)
(20, 224, 224) (20, 224, 224)
finish saving file: patient_016
patient_003.nii
patient_003.nii
patient_005.nii
patient_005.nii
patient_013.nii
patient_013.nii
patient_014.nii
patient_014.nii
patient_016.nii
patient_016.nii
patient_031.nii
patient_031.nii
patient_036.nii
patient_036.nii
patient_038.nii
patient_038.nii
patient_043.nii
patient_043.nii
patient_044.nii
patient_044.nii
patient_060.nii
patient_060.nii
patient_065.nii
patient_065.nii
patient_082.nii
patient_082.nii
patient_093.nii
patient_093.nii
patient_100.nii
patient_100.nii
done
********************
patient_003.nii
********************
patient_003.nii
Dice_rv: 0.2000
Dice_myo: 0.6543
Dice_lv: 0.7962
********************
********************
patient_005.nii
********************
patient_005.nii
Dice_rv: 0.1276
Dice_myo: 0.6389
Dice_lv: 0.8230
********************
********************
patient_013.nii
********************
patient_013.nii
Dice_rv: 0.7096
Dice_myo: 0.7797
Dice_lv: 0.9517
********************
********************
patient_014.nii
********************
patient_014.nii
Dice_rv: 0.0976
Dice_myo: 0.7057
Dice_lv: 0.9332
********************
********************
patient_016.nii
********************
patient_016.nii
Dice_rv: 0.5031
Dice_myo: 0.5592
Dice_lv: 0.8630
********************
********************
patient_031.nii
********************
patient_031.nii
Dice_rv: 0.7633
Dice_myo: 0.7599
Dice_lv: 0.8735
********************
********************
patient_036.nii
********************
patient_036.nii
Dice_rv: 0.7579
Dice_myo: 0.7786
Dice_lv: 0.9386
********************
********************
patient_038.nii
********************
patient_038.nii
Dice_rv: 0.5447
Dice_myo: 0.3907
Dice_lv: 0.9005
********************
********************
patient_043.nii
********************
patient_043.nii
Dice_rv: 0.8296
Dice_myo: 0.6542
Dice_lv: 0.9385
********************
********************
patient_044.nii
********************
patient_044.nii
Dice_rv: 0.2619
Dice_myo: 0.7571
Dice_lv: 0.7980
********************
********************
patient_060.nii
********************
patient_060.nii
Dice_rv: 0.3076
Dice_myo: 0.2220
Dice_lv: 0.4414
********************
********************
patient_065.nii
********************
patient_065.nii
Dice_rv: 0.2518
Dice_myo: 0.2543
Dice_lv: 0.6826
********************
********************
patient_082.nii
********************
patient_082.nii
Dice_rv: 0.0693
Dice_myo: 0.4828
Dice_lv: 0.8165
********************
********************
patient_093.nii
********************
patient_093.nii
Dice_rv: 0.6107
Dice_myo: 0.6570
Dice_lv: 0.7638
********************
********************
patient_100.nii
********************
patient_100.nii
Dice_rv: 0.7003
Dice_myo: 0.6633
Dice_lv: 0.7177
********************
********************
Mean_Dice
Dice_rv0.44899208551162145
Dice_myo0.5971757393083903
Dice_lv0.8158847188699153
Mean_HD
********************
avg_hd:nan
DSC:0.6206841812299757
HD:nan
