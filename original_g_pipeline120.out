/home/kl321/AutoSAM/scripts/main_autosam_seg2.py:116: UserWarning: You have chosen a specific GPU. This will completely disable data parallelism.
  warnings.warn('You have chosen a specific GPU. This will completely '
Use GPU: 0 for training
ImageNet pretrained weights for HarDNet85 is loaded
loaded keys: dict_keys(['image_encoder.neck.0.weight', 'image_encoder.neck.1.weight', 'image_encoder.neck.1.bias', 'image_encoder.neck.2.weight', 'image_encoder.neck.3.weight', 'image_encoder.neck.3.bias', 'image_encoder.patch_embed.proj.weight', 'image_encoder.patch_embed.proj.bias', 'image_encoder.blocks.0.norm1.weight', 'image_encoder.blocks.0.norm1.bias', 'image_encoder.blocks.0.attn.rel_pos_h', 'image_encoder.blocks.0.attn.rel_pos_w', 'image_encoder.blocks.0.attn.qkv.weight', 'image_encoder.blocks.0.attn.qkv.bias', 'image_encoder.blocks.0.attn.proj.weight', 'image_encoder.blocks.0.attn.proj.bias', 'image_encoder.blocks.0.norm2.weight', 'image_encoder.blocks.0.norm2.bias', 'image_encoder.blocks.0.mlp.lin1.weight', 'image_encoder.blocks.0.mlp.lin1.bias', 'image_encoder.blocks.0.mlp.lin2.weight', 'image_encoder.blocks.0.mlp.lin2.bias', 'image_encoder.blocks.1.norm1.weight', 'image_encoder.blocks.1.norm1.bias', 'image_encoder.blocks.1.attn.rel_pos_h', 'image_encoder.blocks.1.attn.rel_pos_w', 'image_encoder.blocks.1.attn.qkv.weight', 'image_encoder.blocks.1.attn.qkv.bias', 'image_encoder.blocks.1.attn.proj.weight', 'image_encoder.blocks.1.attn.proj.bias', 'image_encoder.blocks.1.norm2.weight', 'image_encoder.blocks.1.norm2.bias', 'image_encoder.blocks.1.mlp.lin1.weight', 'image_encoder.blocks.1.mlp.lin1.bias', 'image_encoder.blocks.1.mlp.lin2.weight', 'image_encoder.blocks.1.mlp.lin2.bias', 'image_encoder.blocks.2.norm1.weight', 'image_encoder.blocks.2.norm1.bias', 'image_encoder.blocks.2.attn.rel_pos_h', 'image_encoder.blocks.2.attn.rel_pos_w', 'image_encoder.blocks.2.attn.qkv.weight', 'image_encoder.blocks.2.attn.qkv.bias', 'image_encoder.blocks.2.attn.proj.weight', 'image_encoder.blocks.2.attn.proj.bias', 'image_encoder.blocks.2.norm2.weight', 'image_encoder.blocks.2.norm2.bias', 'image_encoder.blocks.2.mlp.lin1.weight', 'image_encoder.blocks.2.mlp.lin1.bias', 'image_encoder.blocks.2.mlp.lin2.weight', 'image_encoder.blocks.2.mlp.lin2.bias', 'image_encoder.blocks.3.norm1.weight', 'image_encoder.blocks.3.norm1.bias', 'image_encoder.blocks.3.attn.rel_pos_h', 'image_encoder.blocks.3.attn.rel_pos_w', 'image_encoder.blocks.3.attn.qkv.weight', 'image_encoder.blocks.3.attn.qkv.bias', 'image_encoder.blocks.3.attn.proj.weight', 'image_encoder.blocks.3.attn.proj.bias', 'image_encoder.blocks.3.norm2.weight', 'image_encoder.blocks.3.norm2.bias', 'image_encoder.blocks.3.mlp.lin1.weight', 'image_encoder.blocks.3.mlp.lin1.bias', 'image_encoder.blocks.3.mlp.lin2.weight', 'image_encoder.blocks.3.mlp.lin2.bias', 'image_encoder.blocks.4.norm1.weight', 'image_encoder.blocks.4.norm1.bias', 'image_encoder.blocks.4.attn.rel_pos_h', 'image_encoder.blocks.4.attn.rel_pos_w', 'image_encoder.blocks.4.attn.qkv.weight', 'image_encoder.blocks.4.attn.qkv.bias', 'image_encoder.blocks.4.attn.proj.weight', 'image_encoder.blocks.4.attn.proj.bias', 'image_encoder.blocks.4.norm2.weight', 'image_encoder.blocks.4.norm2.bias', 'image_encoder.blocks.4.mlp.lin1.weight', 'image_encoder.blocks.4.mlp.lin1.bias', 'image_encoder.blocks.4.mlp.lin2.weight', 'image_encoder.blocks.4.mlp.lin2.bias', 'image_encoder.blocks.5.norm1.weight', 'image_encoder.blocks.5.norm1.bias', 'image_encoder.blocks.5.attn.rel_pos_h', 'image_encoder.blocks.5.attn.rel_pos_w', 'image_encoder.blocks.5.attn.qkv.weight', 'image_encoder.blocks.5.attn.qkv.bias', 'image_encoder.blocks.5.attn.proj.weight', 'image_encoder.blocks.5.attn.proj.bias', 'image_encoder.blocks.5.norm2.weight', 'image_encoder.blocks.5.norm2.bias', 'image_encoder.blocks.5.mlp.lin1.weight', 'image_encoder.blocks.5.mlp.lin1.bias', 'image_encoder.blocks.5.mlp.lin2.weight', 'image_encoder.blocks.5.mlp.lin2.bias', 'image_encoder.blocks.6.norm1.weight', 'image_encoder.blocks.6.norm1.bias', 'image_encoder.blocks.6.attn.rel_pos_h', 'image_encoder.blocks.6.attn.rel_pos_w', 'image_encoder.blocks.6.attn.qkv.weight', 'image_encoder.blocks.6.attn.qkv.bias', 'image_encoder.blocks.6.attn.proj.weight', 'image_encoder.blocks.6.attn.proj.bias', 'image_encoder.blocks.6.norm2.weight', 'image_encoder.blocks.6.norm2.bias', 'image_encoder.blocks.6.mlp.lin1.weight', 'image_encoder.blocks.6.mlp.lin1.bias', 'image_encoder.blocks.6.mlp.lin2.weight', 'image_encoder.blocks.6.mlp.lin2.bias', 'image_encoder.blocks.7.norm1.weight', 'image_encoder.blocks.7.norm1.bias', 'image_encoder.blocks.7.attn.rel_pos_h', 'image_encoder.blocks.7.attn.rel_pos_w', 'image_encoder.blocks.7.attn.qkv.weight', 'image_encoder.blocks.7.attn.qkv.bias', 'image_encoder.blocks.7.attn.proj.weight', 'image_encoder.blocks.7.attn.proj.bias', 'image_encoder.blocks.7.norm2.weight', 'image_encoder.blocks.7.norm2.bias', 'image_encoder.blocks.7.mlp.lin1.weight', 'image_encoder.blocks.7.mlp.lin1.bias', 'image_encoder.blocks.7.mlp.lin2.weight', 'image_encoder.blocks.7.mlp.lin2.bias', 'image_encoder.blocks.8.norm1.weight', 'image_encoder.blocks.8.norm1.bias', 'image_encoder.blocks.8.attn.rel_pos_h', 'image_encoder.blocks.8.attn.rel_pos_w', 'image_encoder.blocks.8.attn.qkv.weight', 'image_encoder.blocks.8.attn.qkv.bias', 'image_encoder.blocks.8.attn.proj.weight', 'image_encoder.blocks.8.attn.proj.bias', 'image_encoder.blocks.8.norm2.weight', 'image_encoder.blocks.8.norm2.bias', 'image_encoder.blocks.8.mlp.lin1.weight', 'image_encoder.blocks.8.mlp.lin1.bias', 'image_encoder.blocks.8.mlp.lin2.weight', 'image_encoder.blocks.8.mlp.lin2.bias', 'image_encoder.blocks.9.norm1.weight', 'image_encoder.blocks.9.norm1.bias', 'image_encoder.blocks.9.attn.rel_pos_h', 'image_encoder.blocks.9.attn.rel_pos_w', 'image_encoder.blocks.9.attn.qkv.weight', 'image_encoder.blocks.9.attn.qkv.bias', 'image_encoder.blocks.9.attn.proj.weight', 'image_encoder.blocks.9.attn.proj.bias', 'image_encoder.blocks.9.norm2.weight', 'image_encoder.blocks.9.norm2.bias', 'image_encoder.blocks.9.mlp.lin1.weight', 'image_encoder.blocks.9.mlp.lin1.bias', 'image_encoder.blocks.9.mlp.lin2.weight', 'image_encoder.blocks.9.mlp.lin2.bias', 'image_encoder.blocks.10.norm1.weight', 'image_encoder.blocks.10.norm1.bias', 'image_encoder.blocks.10.attn.rel_pos_h', 'image_encoder.blocks.10.attn.rel_pos_w', 'image_encoder.blocks.10.attn.qkv.weight', 'image_encoder.blocks.10.attn.qkv.bias', 'image_encoder.blocks.10.attn.proj.weight', 'image_encoder.blocks.10.attn.proj.bias', 'image_encoder.blocks.10.norm2.weight', 'image_encoder.blocks.10.norm2.bias', 'image_encoder.blocks.10.mlp.lin1.weight', 'image_encoder.blocks.10.mlp.lin1.bias', 'image_encoder.blocks.10.mlp.lin2.weight', 'image_encoder.blocks.10.mlp.lin2.bias', 'image_encoder.blocks.11.norm1.weight', 'image_encoder.blocks.11.norm1.bias', 'image_encoder.blocks.11.attn.rel_pos_h', 'image_encoder.blocks.11.attn.rel_pos_w', 'image_encoder.blocks.11.attn.qkv.weight', 'image_encoder.blocks.11.attn.qkv.bias', 'image_encoder.blocks.11.attn.proj.weight', 'image_encoder.blocks.11.attn.proj.bias', 'image_encoder.blocks.11.norm2.weight', 'image_encoder.blocks.11.norm2.bias', 'image_encoder.blocks.11.mlp.lin1.weight', 'image_encoder.blocks.11.mlp.lin1.bias', 'image_encoder.blocks.11.mlp.lin2.weight', 'image_encoder.blocks.11.mlp.lin2.bias', 'mask_decoder.transformer.layers.0.self_attn.q_proj.weight', 'mask_decoder.transformer.layers.0.self_attn.q_proj.bias', 'mask_decoder.transformer.layers.0.self_attn.k_proj.weight', 'mask_decoder.transformer.layers.0.self_attn.k_proj.bias', 'mask_decoder.transformer.layers.0.self_attn.v_proj.weight', 'mask_decoder.transformer.layers.0.self_attn.v_proj.bias', 'mask_decoder.transformer.layers.0.self_attn.out_proj.weight', 'mask_decoder.transformer.layers.0.self_attn.out_proj.bias', 'mask_decoder.transformer.layers.0.norm1.weight', 'mask_decoder.transformer.layers.0.norm1.bias', 'mask_decoder.transformer.layers.0.cross_attn_token_to_image.q_proj.weight', 'mask_decoder.transformer.layers.0.cross_attn_token_to_image.q_proj.bias', 'mask_decoder.transformer.layers.0.cross_attn_token_to_image.k_proj.weight', 'mask_decoder.transformer.layers.0.cross_attn_token_to_image.k_proj.bias', 'mask_decoder.transformer.layers.0.cross_attn_token_to_image.v_proj.weight', 'mask_decoder.transformer.layers.0.cross_attn_token_to_image.v_proj.bias', 'mask_decoder.transformer.layers.0.cross_attn_token_to_image.out_proj.weight', 'mask_decoder.transformer.layers.0.cross_attn_token_to_image.out_proj.bias', 'mask_decoder.transformer.layers.0.norm2.weight', 'mask_decoder.transformer.layers.0.norm2.bias', 'mask_decoder.transformer.layers.0.mlp.lin1.weight', 'mask_decoder.transformer.layers.0.mlp.lin1.bias', 'mask_decoder.transformer.layers.0.mlp.lin2.weight', 'mask_decoder.transformer.layers.0.mlp.lin2.bias', 'mask_decoder.transformer.layers.0.norm3.weight', 'mask_decoder.transformer.layers.0.norm3.bias', 'mask_decoder.transformer.layers.0.norm4.weight', 'mask_decoder.transformer.layers.0.norm4.bias', 'mask_decoder.transformer.layers.0.cross_attn_image_to_token.q_proj.weight', 'mask_decoder.transformer.layers.0.cross_attn_image_to_token.q_proj.bias', 'mask_decoder.transformer.layers.0.cross_attn_image_to_token.k_proj.weight', 'mask_decoder.transformer.layers.0.cross_attn_image_to_token.k_proj.bias', 'mask_decoder.transformer.layers.0.cross_attn_image_to_token.v_proj.weight', 'mask_decoder.transformer.layers.0.cross_attn_image_to_token.v_proj.bias', 'mask_decoder.transformer.layers.0.cross_attn_image_to_token.out_proj.weight', 'mask_decoder.transformer.layers.0.cross_attn_image_to_token.out_proj.bias', 'mask_decoder.transformer.layers.1.self_attn.q_proj.weight', 'mask_decoder.transformer.layers.1.self_attn.q_proj.bias', 'mask_decoder.transformer.layers.1.self_attn.k_proj.weight', 'mask_decoder.transformer.layers.1.self_attn.k_proj.bias', 'mask_decoder.transformer.layers.1.self_attn.v_proj.weight', 'mask_decoder.transformer.layers.1.self_attn.v_proj.bias', 'mask_decoder.transformer.layers.1.self_attn.out_proj.weight', 'mask_decoder.transformer.layers.1.self_attn.out_proj.bias', 'mask_decoder.transformer.layers.1.norm1.weight', 'mask_decoder.transformer.layers.1.norm1.bias', 'mask_decoder.transformer.layers.1.cross_attn_token_to_image.q_proj.weight', 'mask_decoder.transformer.layers.1.cross_attn_token_to_image.q_proj.bias', 'mask_decoder.transformer.layers.1.cross_attn_token_to_image.k_proj.weight', 'mask_decoder.transformer.layers.1.cross_attn_token_to_image.k_proj.bias', 'mask_decoder.transformer.layers.1.cross_attn_token_to_image.v_proj.weight', 'mask_decoder.transformer.layers.1.cross_attn_token_to_image.v_proj.bias', 'mask_decoder.transformer.layers.1.cross_attn_token_to_image.out_proj.weight', 'mask_decoder.transformer.layers.1.cross_attn_token_to_image.out_proj.bias', 'mask_decoder.transformer.layers.1.norm2.weight', 'mask_decoder.transformer.layers.1.norm2.bias', 'mask_decoder.transformer.layers.1.mlp.lin1.weight', 'mask_decoder.transformer.layers.1.mlp.lin1.bias', 'mask_decoder.transformer.layers.1.mlp.lin2.weight', 'mask_decoder.transformer.layers.1.mlp.lin2.bias', 'mask_decoder.transformer.layers.1.norm3.weight', 'mask_decoder.transformer.layers.1.norm3.bias', 'mask_decoder.transformer.layers.1.norm4.weight', 'mask_decoder.transformer.layers.1.norm4.bias', 'mask_decoder.transformer.layers.1.cross_attn_image_to_token.q_proj.weight', 'mask_decoder.transformer.layers.1.cross_attn_image_to_token.q_proj.bias', 'mask_decoder.transformer.layers.1.cross_attn_image_to_token.k_proj.weight', 'mask_decoder.transformer.layers.1.cross_attn_image_to_token.k_proj.bias', 'mask_decoder.transformer.layers.1.cross_attn_image_to_token.v_proj.weight', 'mask_decoder.transformer.layers.1.cross_attn_image_to_token.v_proj.bias', 'mask_decoder.transformer.layers.1.cross_attn_image_to_token.out_proj.weight', 'mask_decoder.transformer.layers.1.cross_attn_image_to_token.out_proj.bias', 'mask_decoder.transformer.final_attn_token_to_image.q_proj.weight', 'mask_decoder.transformer.final_attn_token_to_image.q_proj.bias', 'mask_decoder.transformer.final_attn_token_to_image.k_proj.weight', 'mask_decoder.transformer.final_attn_token_to_image.k_proj.bias', 'mask_decoder.transformer.final_attn_token_to_image.v_proj.weight', 'mask_decoder.transformer.final_attn_token_to_image.v_proj.bias', 'mask_decoder.transformer.final_attn_token_to_image.out_proj.weight', 'mask_decoder.transformer.final_attn_token_to_image.out_proj.bias', 'mask_decoder.transformer.norm_final_attn.weight', 'mask_decoder.transformer.norm_final_attn.bias', 'mask_decoder.output_upscaling.0.weight', 'mask_decoder.output_upscaling.0.bias', 'mask_decoder.output_upscaling.1.weight', 'mask_decoder.output_upscaling.1.bias', 'mask_decoder.output_upscaling.3.weight', 'mask_decoder.output_upscaling.3.bias', 'mask_decoder.output_hypernetworks_mlps.0.layers.0.weight', 'mask_decoder.output_hypernetworks_mlps.0.layers.0.bias', 'mask_decoder.output_hypernetworks_mlps.0.layers.1.weight', 'mask_decoder.output_hypernetworks_mlps.0.layers.1.bias', 'mask_decoder.output_hypernetworks_mlps.0.layers.2.weight', 'mask_decoder.output_hypernetworks_mlps.0.layers.2.bias', 'mask_decoder.output_hypernetworks_mlps.1.layers.0.weight', 'mask_decoder.output_hypernetworks_mlps.1.layers.0.bias', 'mask_decoder.output_hypernetworks_mlps.1.layers.1.weight', 'mask_decoder.output_hypernetworks_mlps.1.layers.1.bias', 'mask_decoder.output_hypernetworks_mlps.1.layers.2.weight', 'mask_decoder.output_hypernetworks_mlps.1.layers.2.bias', 'image_encoder.pos_embed'])
['patient_035']
['patient_057', 'patient_028', 'patient_087', 'patient_061', 'patient_032', 'patient_011', 'patient_078', 'patient_009', 'patient_068', 'patient_021', 'patient_079', 'patient_004', 'patient_089', 'patient_023', 'patient_070']
['patient_014', 'patient_060', 'patient_044', 'patient_036', 'patient_003', 'patient_100', 'patient_065', 'patient_013', 'patient_038', 'patient_093', 'patient_043', 'patient_082', 'patient_031', 'patient_005', 'patient_016']
dataset length: 26
dataset length: 258
dataset length: 296
output_experiment/original_g120
Train: [0][0/7]	loss 2.8179
Validating: Epoch:  0 Loss: 0.9706 IoU_pred: -0.0929
Train: [1][0/7]	loss 1.4971
Validating: Epoch:  1 Loss: 0.9500 IoU_pred: -0.3361
Train: [2][0/7]	loss 1.2219
Validating: Epoch:  2 Loss: 0.9347 IoU_pred: -0.3500
Train: [3][0/7]	loss 1.2736
Validating: Epoch:  3 Loss: 0.9392 IoU_pred: -0.3444
Train: [4][0/7]	loss 1.2809
Validating: Epoch:  4 Loss: 0.9433 IoU_pred: -0.3542
Train: [5][0/7]	loss 1.2285
Validating: Epoch:  5 Loss: 0.9486 IoU_pred: -0.3443
Train: [6][0/7]	loss 1.1132
Validating: Epoch:  6 Loss: 0.9474 IoU_pred: -0.3370
Train: [7][0/7]	loss 1.1422
Validating: Epoch:  7 Loss: 0.9512 IoU_pred: -0.3236
Train: [8][0/7]	loss 1.1516
Validating: Epoch:  8 Loss: 0.9520 IoU_pred: -0.3279
Train: [9][0/7]	loss 1.1302
Validating: Epoch:  9 Loss: 0.9507 IoU_pred: -0.2917
Train: [10][0/7]	loss 1.1774
Validating: Epoch: 10 Loss: 0.9398 IoU_pred: -0.2654
Train: [11][0/7]	loss 1.1436
Validating: Epoch: 11 Loss: 0.9608 IoU_pred: -0.2527
Train: [12][0/7]	loss 1.1818
Validating: Epoch: 12 Loss: 0.9678 IoU_pred: -0.2429
Train: [13][0/7]	loss 1.1402
Validating: Epoch: 13 Loss: 0.9499 IoU_pred: -0.2442
Train: [14][0/7]	loss 1.1829
Validating: Epoch: 14 Loss: 0.9264 IoU_pred: -0.1914
Train: [15][0/7]	loss 1.1728
Validating: Epoch: 15 Loss: 0.9353 IoU_pred: -0.2395
Train: [16][0/7]	loss 1.2937
Validating: Epoch: 16 Loss: 0.9370 IoU_pred: -0.2712
Train: [17][0/7]	loss 1.1972
Validating: Epoch: 17 Loss: 0.9628 IoU_pred: -0.2317
Train: [18][0/7]	loss 1.1540
Validating: Epoch: 18 Loss: 0.9484 IoU_pred: -0.2399
Train: [19][0/7]	loss 1.2812
Validating: Epoch: 19 Loss: 0.9695 IoU_pred: -0.1802
Train: [20][0/7]	loss 1.1559
Validating: Epoch: 20 Loss: 0.9737 IoU_pred: -0.1831
Train: [21][0/7]	loss 1.1212
Validating: Epoch: 21 Loss: 0.9485 IoU_pred: -0.1911
Train: [22][0/7]	loss 1.1128
Validating: Epoch: 22 Loss: 0.9011 IoU_pred: -0.1896
Train: [23][0/7]	loss 1.1898
Validating: Epoch: 23 Loss: 0.9254 IoU_pred: -0.2423
Train: [24][0/7]	loss 1.2630
Validating: Epoch: 24 Loss: 0.9465 IoU_pred: -0.3221
Train: [25][0/7]	loss 1.1786
Validating: Epoch: 25 Loss: 0.9292 IoU_pred: -0.2591
Train: [26][0/7]	loss 1.1940
Validating: Epoch: 26 Loss: 0.9680 IoU_pred: -0.2572
Train: [27][0/7]	loss 1.0837
Validating: Epoch: 27 Loss: 0.9573 IoU_pred: -0.1386
Train: [28][0/7]	loss 1.5778
Validating: Epoch: 28 Loss: 0.9856 IoU_pred: -0.3255
Train: [29][0/7]	loss 1.1586
Validating: Epoch: 29 Loss: 0.9897 IoU_pred: -0.3048
Train: [30][0/7]	loss 1.0978
Validating: Epoch: 30 Loss: 0.9906 IoU_pred: -0.2561
Train: [31][0/7]	loss 1.1558
Validating: Epoch: 31 Loss: 0.9743 IoU_pred: -0.2653
Train: [32][0/7]	loss 1.1237
Validating: Epoch: 32 Loss: 0.9714 IoU_pred: -0.2321
Train: [33][0/7]	loss 1.1632
Validating: Epoch: 33 Loss: 0.9713 IoU_pred: -0.1926
Train: [34][0/7]	loss 1.2211
Validating: Epoch: 34 Loss: 0.9701 IoU_pred: -0.2509
Train: [35][0/7]	loss 1.1151
Validating: Epoch: 35 Loss: 0.9690 IoU_pred: -0.2441
Train: [36][0/7]	loss 1.3169
Validating: Epoch: 36 Loss: 0.9632 IoU_pred: -0.2366
Train: [37][0/7]	loss 1.1446
Validating: Epoch: 37 Loss: 0.9527 IoU_pred: -0.2536
Train: [38][0/7]	loss 1.1105
Validating: Epoch: 38 Loss: 0.9480 IoU_pred: -0.2866
Train: [39][0/7]	loss 1.1060
Validating: Epoch: 39 Loss: 0.9330 IoU_pred: -0.2524
Train: [40][0/7]	loss 1.0613
Validating: Epoch: 40 Loss: 0.9103 IoU_pred: -0.2786
Train: [41][0/7]	loss 1.1650
Validating: Epoch: 41 Loss: 0.9171 IoU_pred: -0.2453
Train: [42][0/7]	loss 1.1315
Validating: Epoch: 42 Loss: 0.9522 IoU_pred: -0.2787
Train: [43][0/7]	loss 1.0164
Validating: Epoch: 43 Loss: 0.9425 IoU_pred: -0.2565
Train: [44][0/7]	loss 1.0884
Validating: Epoch: 44 Loss: 0.9321 IoU_pred: -0.2477
Train: [45][0/7]	loss 1.0468
Validating: Epoch: 45 Loss: 0.9311 IoU_pred: -0.2723
Train: [46][0/7]	loss 1.0642
Validating: Epoch: 46 Loss: 0.8985 IoU_pred: -0.2580
Train: [47][0/7]	loss 1.1142
Validating: Epoch: 47 Loss: 0.9090 IoU_pred: -0.2602
Train: [48][0/7]	loss 1.0888
Validating: Epoch: 48 Loss: 0.9254 IoU_pred: -0.2264
Train: [49][0/7]	loss 1.1047
Validating: Epoch: 49 Loss: 0.9092 IoU_pred: -0.2270
Train: [50][0/7]	loss 1.0939
Validating: Epoch: 50 Loss: 0.9031 IoU_pred: -0.2447
Train: [51][0/7]	loss 1.1344
Validating: Epoch: 51 Loss: 0.9372 IoU_pred: -0.1965
Train: [52][0/7]	loss 1.1381
Validating: Epoch: 52 Loss: 0.9408 IoU_pred: -0.2437
Train: [53][0/7]	loss 1.0420
Validating: Epoch: 53 Loss: 0.9373 IoU_pred: -0.2633
Train: [54][0/7]	loss 1.1699
Validating: Epoch: 54 Loss: 0.9140 IoU_pred: -0.2234
Train: [55][0/7]	loss 1.0686
Validating: Epoch: 55 Loss: 0.9481 IoU_pred: -0.2449
Train: [56][0/7]	loss 1.0797
Validating: Epoch: 56 Loss: 0.9468 IoU_pred: -0.2541
Train: [57][0/7]	loss 1.0808
Validating: Epoch: 57 Loss: 0.9119 IoU_pred: -0.2541
Train: [58][0/7]	loss 1.1883
Validating: Epoch: 58 Loss: 0.9023 IoU_pred: -0.2645
Train: [59][0/7]	loss 1.1262
Validating: Epoch: 59 Loss: 0.9008 IoU_pred: -0.2675
Train: [60][0/7]	loss 1.2052
Validating: Epoch: 60 Loss: 0.9230 IoU_pred: -0.2641
Train: [61][0/7]	loss 1.0850
Validating: Epoch: 61 Loss: 0.9174 IoU_pred: -0.2805
Train: [62][0/7]	loss 1.0775
Validating: Epoch: 62 Loss: 0.9113 IoU_pred: -0.2569
Train: [63][0/7]	loss 1.0224
Validating: Epoch: 63 Loss: 0.9054 IoU_pred: -0.2631
Train: [64][0/7]	loss 1.0897
Validating: Epoch: 64 Loss: 0.8997 IoU_pred: -0.2677
Train: [65][0/7]	loss 1.0903
Validating: Epoch: 65 Loss: 0.9387 IoU_pred: -0.2602
Train: [66][0/7]	loss 1.0638
Validating: Epoch: 66 Loss: 0.9243 IoU_pred: -0.2565
Train: [67][0/7]	loss 1.1675
Validating: Epoch: 67 Loss: 0.9076 IoU_pred: -0.2337
Train: [68][0/7]	loss 1.2820
Validating: Epoch: 68 Loss: 0.9141 IoU_pred: -0.2147
Train: [69][0/7]	loss 1.0592
Validating: Epoch: 69 Loss: 0.8939 IoU_pred: -0.2559
Train: [70][0/7]	loss 1.0419
Validating: Epoch: 70 Loss: 0.9224 IoU_pred: -0.2450
Train: [71][0/7]	loss 1.1006
Validating: Epoch: 71 Loss: 0.9174 IoU_pred: -0.2529
Train: [72][0/7]	loss 1.0597
Validating: Epoch: 72 Loss: 0.8976 IoU_pred: -0.2632
Train: [73][0/7]	loss 0.9780
Validating: Epoch: 73 Loss: 0.9456 IoU_pred: -0.2836
Train: [74][0/7]	loss 1.1271
Validating: Epoch: 74 Loss: 0.9300 IoU_pred: -0.2508
Train: [75][0/7]	loss 1.0631
Validating: Epoch: 75 Loss: 0.9104 IoU_pred: -0.2692
Train: [76][0/7]	loss 1.0478
Validating: Epoch: 76 Loss: 0.9399 IoU_pred: -0.2570
Train: [77][0/7]	loss 1.1528
Validating: Epoch: 77 Loss: 0.9408 IoU_pred: -0.2426
Train: [78][0/7]	loss 1.0351
Validating: Epoch: 78 Loss: 0.9199 IoU_pred: -0.2750
Train: [79][0/7]	loss 1.1671
Validating: Epoch: 79 Loss: 0.9113 IoU_pred: -0.2515
Train: [80][0/7]	loss 1.3187
Validating: Epoch: 80 Loss: 0.9232 IoU_pred: -0.2696
Train: [81][0/7]	loss 1.1117
Validating: Epoch: 81 Loss: 0.9079 IoU_pred: -0.2394
Train: [82][0/7]	loss 1.0538
Validating: Epoch: 82 Loss: 0.8910 IoU_pred: -0.2793
Train: [83][0/7]	loss 1.0994
Validating: Epoch: 83 Loss: 0.8942 IoU_pred: -0.2373
Train: [84][0/7]	loss 1.1205
Validating: Epoch: 84 Loss: 0.9367 IoU_pred: -0.2738
Train: [85][0/7]	loss 1.0431
Validating: Epoch: 85 Loss: 0.9529 IoU_pred: -0.2655
Train: [86][0/7]	loss 1.0660
Validating: Epoch: 86 Loss: 0.9297 IoU_pred: -0.2502
Train: [87][0/7]	loss 1.4722
Validating: Epoch: 87 Loss: 0.9136 IoU_pred: -0.2507
Train: [88][0/7]	loss 1.0437
Validating: Epoch: 88 Loss: 0.9016 IoU_pred: -0.2752
Train: [89][0/7]	loss 1.0666
Validating: Epoch: 89 Loss: 0.9235 IoU_pred: -0.2622
Train: [90][0/7]	loss 1.2181
Validating: Epoch: 90 Loss: 0.9168 IoU_pred: -0.2751
Train: [91][0/7]	loss 1.0953
Validating: Epoch: 91 Loss: 0.8988 IoU_pred: -0.2811
Train: [92][0/7]	loss 1.1380
Validating: Epoch: 92 Loss: 0.8786 IoU_pred: -0.2520
Train: [93][0/7]	loss 1.0889
Validating: Epoch: 93 Loss: 0.9419 IoU_pred: -0.2610
Train: [94][0/7]	loss 1.2627
Validating: Epoch: 94 Loss: 0.8925 IoU_pred: -0.2444
Train: [95][0/7]	loss 1.2227
Validating: Epoch: 95 Loss: 0.8996 IoU_pred: -0.2520
Train: [96][0/7]	loss 1.0235
Validating: Epoch: 96 Loss: 0.8983 IoU_pred: -0.2600
Train: [97][0/7]	loss 1.1333
Validating: Epoch: 97 Loss: 0.8995 IoU_pred: -0.2705
Train: [98][0/7]	loss 1.0334
Validating: Epoch: 98 Loss: 0.8919 IoU_pred: -0.2682
Train: [99][0/7]	loss 1.4823
Validating: Epoch: 99 Loss: 0.9368 IoU_pred: -0.2394
Train: [100][0/7]	loss 1.2163
Validating: Epoch: 100 Loss: 0.9224 IoU_pred: -0.2564
Train: [101][0/7]	loss 1.0660
Validating: Epoch: 101 Loss: 0.9430 IoU_pred: -0.2970
Train: [102][0/7]	loss 1.0720
Validating: Epoch: 102 Loss: 0.9189 IoU_pred: -0.2862
Train: [103][0/7]	loss 1.2999
Validating: Epoch: 103 Loss: 0.8959 IoU_pred: -0.2952
Train: [104][0/7]	loss 1.1508
Validating: Epoch: 104 Loss: 0.9003 IoU_pred: -0.2748
Train: [105][0/7]	loss 1.1073
Validating: Epoch: 105 Loss: 0.9028 IoU_pred: -0.2307
Train: [106][0/7]	loss 1.0383
Validating: Epoch: 106 Loss: 0.9165 IoU_pred: -0.2474
Train: [107][0/7]	loss 1.1741
Validating: Epoch: 107 Loss: 0.9082 IoU_pred: -0.2647
Train: [108][0/7]	loss 1.1142
Validating: Epoch: 108 Loss: 0.8959 IoU_pred: -0.2876
Train: [109][0/7]	loss 1.0815
Validating: Epoch: 109 Loss: 0.9024 IoU_pred: -0.2442
Train: [110][0/7]	loss 1.0385
Validating: Epoch: 110 Loss: 0.9060 IoU_pred: -0.2552
Train: [111][0/7]	loss 1.0463
Validating: Epoch: 111 Loss: 0.9072 IoU_pred: -0.2859
Train: [112][0/7]	loss 1.0813
Validating: Epoch: 112 Loss: 0.9372 IoU_pred: -0.2868
Train: [113][0/7]	loss 1.1860
Validating: Epoch: 113 Loss: 0.9401 IoU_pred: -0.2605
Train: [114][0/7]	loss 1.0268
Validating: Epoch: 114 Loss: 0.9089 IoU_pred: -0.2696
Train: [115][0/7]	loss 1.0671
Validating: Epoch: 115 Loss: 0.9421 IoU_pred: -0.2740
Train: [116][0/7]	loss 1.0204
Validating: Epoch: 116 Loss: 0.9392 IoU_pred: -0.2301
Train: [117][0/7]	loss 1.0758
Validating: Epoch: 117 Loss: 0.9176 IoU_pred: -0.2771
Train: [118][0/7]	loss 1.1034
Validating: Epoch: 118 Loss: 0.9334 IoU_pred: -0.2660
Train: [119][0/7]	loss 1.0066
Validating: Epoch: 119 Loss: 0.9215 IoU_pred: -0.2794
Test
dataset length: 20
(20, 224, 224) (20, 224, 224)
finish saving file: patient_014
dataset length: 18
(18, 224, 224) (18, 224, 224)
finish saving file: patient_060
dataset length: 18
(18, 224, 224) (18, 224, 224)
finish saving file: patient_044
dataset length: 16
(16, 224, 224) (16, 224, 224)
finish saving file: patient_036
dataset length: 20
(20, 224, 224) (20, 224, 224)
finish saving file: patient_003
dataset length: 16
(16, 224, 224) (16, 224, 224)
finish saving file: patient_100
dataset length: 16
(16, 224, 224) (16, 224, 224)
finish saving file: patient_065
dataset length: 20
(20, 224, 224) (20, 224, 224)
finish saving file: patient_013
dataset length: 16
(16, 224, 224) (16, 224, 224)
finish saving file: patient_038
dataset length: 20
(20, 224, 224) (20, 224, 224)
finish saving file: patient_093
dataset length: 24
(24, 224, 224) (24, 224, 224)
finish saving file: patient_043
dataset length: 32
(32, 224, 224) (32, 224, 224)
finish saving file: patient_082
dataset length: 20
(20, 224, 224) (20, 224, 224)
finish saving file: patient_031
dataset length: 20
(20, 224, 224) (20, 224, 224)
finish saving file: patient_005
dataset length: 20
/home/kl321/miniconda3/envs/medsam/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.
  return _methods._mean(a, axis=axis, dtype=dtype,
/home/kl321/miniconda3/envs/medsam/lib/python3.10/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)
(20, 224, 224) (20, 224, 224)
finish saving file: patient_016
patient_003.nii
patient_003.nii
patient_005.nii
patient_005.nii
patient_013.nii
patient_013.nii
patient_014.nii
patient_014.nii
patient_016.nii
patient_016.nii
patient_031.nii
patient_031.nii
patient_036.nii
patient_036.nii
patient_038.nii
patient_038.nii
patient_043.nii
patient_043.nii
patient_044.nii
patient_044.nii
patient_060.nii
patient_060.nii
patient_065.nii
patient_065.nii
patient_082.nii
patient_082.nii
patient_093.nii
patient_093.nii
patient_100.nii
patient_100.nii
done
********************
patient_003.nii
********************
patient_003.nii
Dice_rv: 0.0000
Dice_myo: 0.0000
Dice_lv: 0.0105
********************
********************
patient_005.nii
********************
patient_005.nii
Dice_rv: 0.0000
Dice_myo: 0.0000
Dice_lv: 0.0605
********************
********************
patient_013.nii
********************
patient_013.nii
Dice_rv: 0.0000
Dice_myo: 0.0000
Dice_lv: 0.2037
********************
********************
patient_014.nii
********************
patient_014.nii
Dice_rv: 0.0000
Dice_myo: 0.0007
Dice_lv: 0.1096
********************
********************
patient_016.nii
********************
patient_016.nii
Dice_rv: 0.0000
Dice_myo: 0.0000
Dice_lv: 0.0940
********************
********************
patient_031.nii
********************
patient_031.nii
Dice_rv: 0.0000
Dice_myo: 0.0000
Dice_lv: 0.0604
********************
********************
patient_036.nii
********************
patient_036.nii
Dice_rv: 0.0000
Dice_myo: 0.0000
Dice_lv: 0.0661
********************
********************
patient_038.nii
********************
patient_038.nii
Dice_rv: 0.0000
Dice_myo: 0.0000
Dice_lv: 0.1210
********************
********************
patient_043.nii
********************
patient_043.nii
Dice_rv: 0.0000
Dice_myo: 0.0000
Dice_lv: 0.0013
********************
********************
patient_044.nii
********************
patient_044.nii
Dice_rv: 0.0000
Dice_myo: 0.0000
Dice_lv: 0.0036
********************
********************
patient_060.nii
********************
patient_060.nii
Dice_rv: 0.0000
Dice_myo: 0.0000
Dice_lv: 0.1233
********************
********************
patient_065.nii
********************
patient_065.nii
Dice_rv: 0.0000
Dice_myo: 0.0023
Dice_lv: 0.0143
********************
********************
patient_082.nii
********************
patient_082.nii
Dice_rv: 0.0000
Dice_myo: 0.0000
Dice_lv: 0.0442
********************
********************
patient_093.nii
********************
patient_093.nii
Dice_rv: 0.0000
Dice_myo: 0.0000
Dice_lv: 0.0270
********************
********************
patient_100.nii
********************
patient_100.nii
Dice_rv: 0.0000
Dice_myo: 0.0000
Dice_lv: 0.0132
********************
********************
Mean_Dice
Dice_rv0.0
Dice_myo0.00020025355389869214
Dice_lv0.06352672155300836
Mean_HD
********************
avg_hd:nan
DSC:0.02124232503563568
HD:nan
