/home/kl321/AutoSAM/scripts/main_autosam_seg2.py:116: UserWarning: You have chosen a specific GPU. This will completely disable data parallelism.
  warnings.warn('You have chosen a specific GPU. This will completely '
Use GPU: 0 for training
ImageNet pretrained weights for HarDNet85 is loaded
loaded keys: dict_keys(['image_encoder.neck.0.weight', 'image_encoder.neck.1.weight', 'image_encoder.neck.1.bias', 'image_encoder.neck.2.weight', 'image_encoder.neck.3.weight', 'image_encoder.neck.3.bias', 'image_encoder.patch_embed.proj.weight', 'image_encoder.patch_embed.proj.bias', 'image_encoder.blocks.0.norm1.weight', 'image_encoder.blocks.0.norm1.bias', 'image_encoder.blocks.0.attn.rel_pos_h', 'image_encoder.blocks.0.attn.rel_pos_w', 'image_encoder.blocks.0.attn.qkv.weight', 'image_encoder.blocks.0.attn.qkv.bias', 'image_encoder.blocks.0.attn.proj.weight', 'image_encoder.blocks.0.attn.proj.bias', 'image_encoder.blocks.0.norm2.weight', 'image_encoder.blocks.0.norm2.bias', 'image_encoder.blocks.0.mlp.lin1.weight', 'image_encoder.blocks.0.mlp.lin1.bias', 'image_encoder.blocks.0.mlp.lin2.weight', 'image_encoder.blocks.0.mlp.lin2.bias', 'image_encoder.blocks.1.norm1.weight', 'image_encoder.blocks.1.norm1.bias', 'image_encoder.blocks.1.attn.rel_pos_h', 'image_encoder.blocks.1.attn.rel_pos_w', 'image_encoder.blocks.1.attn.qkv.weight', 'image_encoder.blocks.1.attn.qkv.bias', 'image_encoder.blocks.1.attn.proj.weight', 'image_encoder.blocks.1.attn.proj.bias', 'image_encoder.blocks.1.norm2.weight', 'image_encoder.blocks.1.norm2.bias', 'image_encoder.blocks.1.mlp.lin1.weight', 'image_encoder.blocks.1.mlp.lin1.bias', 'image_encoder.blocks.1.mlp.lin2.weight', 'image_encoder.blocks.1.mlp.lin2.bias', 'image_encoder.blocks.2.norm1.weight', 'image_encoder.blocks.2.norm1.bias', 'image_encoder.blocks.2.attn.rel_pos_h', 'image_encoder.blocks.2.attn.rel_pos_w', 'image_encoder.blocks.2.attn.qkv.weight', 'image_encoder.blocks.2.attn.qkv.bias', 'image_encoder.blocks.2.attn.proj.weight', 'image_encoder.blocks.2.attn.proj.bias', 'image_encoder.blocks.2.norm2.weight', 'image_encoder.blocks.2.norm2.bias', 'image_encoder.blocks.2.mlp.lin1.weight', 'image_encoder.blocks.2.mlp.lin1.bias', 'image_encoder.blocks.2.mlp.lin2.weight', 'image_encoder.blocks.2.mlp.lin2.bias', 'image_encoder.blocks.3.norm1.weight', 'image_encoder.blocks.3.norm1.bias', 'image_encoder.blocks.3.attn.rel_pos_h', 'image_encoder.blocks.3.attn.rel_pos_w', 'image_encoder.blocks.3.attn.qkv.weight', 'image_encoder.blocks.3.attn.qkv.bias', 'image_encoder.blocks.3.attn.proj.weight', 'image_encoder.blocks.3.attn.proj.bias', 'image_encoder.blocks.3.norm2.weight', 'image_encoder.blocks.3.norm2.bias', 'image_encoder.blocks.3.mlp.lin1.weight', 'image_encoder.blocks.3.mlp.lin1.bias', 'image_encoder.blocks.3.mlp.lin2.weight', 'image_encoder.blocks.3.mlp.lin2.bias', 'image_encoder.blocks.4.norm1.weight', 'image_encoder.blocks.4.norm1.bias', 'image_encoder.blocks.4.attn.rel_pos_h', 'image_encoder.blocks.4.attn.rel_pos_w', 'image_encoder.blocks.4.attn.qkv.weight', 'image_encoder.blocks.4.attn.qkv.bias', 'image_encoder.blocks.4.attn.proj.weight', 'image_encoder.blocks.4.attn.proj.bias', 'image_encoder.blocks.4.norm2.weight', 'image_encoder.blocks.4.norm2.bias', 'image_encoder.blocks.4.mlp.lin1.weight', 'image_encoder.blocks.4.mlp.lin1.bias', 'image_encoder.blocks.4.mlp.lin2.weight', 'image_encoder.blocks.4.mlp.lin2.bias', 'image_encoder.blocks.5.norm1.weight', 'image_encoder.blocks.5.norm1.bias', 'image_encoder.blocks.5.attn.rel_pos_h', 'image_encoder.blocks.5.attn.rel_pos_w', 'image_encoder.blocks.5.attn.qkv.weight', 'image_encoder.blocks.5.attn.qkv.bias', 'image_encoder.blocks.5.attn.proj.weight', 'image_encoder.blocks.5.attn.proj.bias', 'image_encoder.blocks.5.norm2.weight', 'image_encoder.blocks.5.norm2.bias', 'image_encoder.blocks.5.mlp.lin1.weight', 'image_encoder.blocks.5.mlp.lin1.bias', 'image_encoder.blocks.5.mlp.lin2.weight', 'image_encoder.blocks.5.mlp.lin2.bias', 'image_encoder.blocks.6.norm1.weight', 'image_encoder.blocks.6.norm1.bias', 'image_encoder.blocks.6.attn.rel_pos_h', 'image_encoder.blocks.6.attn.rel_pos_w', 'image_encoder.blocks.6.attn.qkv.weight', 'image_encoder.blocks.6.attn.qkv.bias', 'image_encoder.blocks.6.attn.proj.weight', 'image_encoder.blocks.6.attn.proj.bias', 'image_encoder.blocks.6.norm2.weight', 'image_encoder.blocks.6.norm2.bias', 'image_encoder.blocks.6.mlp.lin1.weight', 'image_encoder.blocks.6.mlp.lin1.bias', 'image_encoder.blocks.6.mlp.lin2.weight', 'image_encoder.blocks.6.mlp.lin2.bias', 'image_encoder.blocks.7.norm1.weight', 'image_encoder.blocks.7.norm1.bias', 'image_encoder.blocks.7.attn.rel_pos_h', 'image_encoder.blocks.7.attn.rel_pos_w', 'image_encoder.blocks.7.attn.qkv.weight', 'image_encoder.blocks.7.attn.qkv.bias', 'image_encoder.blocks.7.attn.proj.weight', 'image_encoder.blocks.7.attn.proj.bias', 'image_encoder.blocks.7.norm2.weight', 'image_encoder.blocks.7.norm2.bias', 'image_encoder.blocks.7.mlp.lin1.weight', 'image_encoder.blocks.7.mlp.lin1.bias', 'image_encoder.blocks.7.mlp.lin2.weight', 'image_encoder.blocks.7.mlp.lin2.bias', 'image_encoder.blocks.8.norm1.weight', 'image_encoder.blocks.8.norm1.bias', 'image_encoder.blocks.8.attn.rel_pos_h', 'image_encoder.blocks.8.attn.rel_pos_w', 'image_encoder.blocks.8.attn.qkv.weight', 'image_encoder.blocks.8.attn.qkv.bias', 'image_encoder.blocks.8.attn.proj.weight', 'image_encoder.blocks.8.attn.proj.bias', 'image_encoder.blocks.8.norm2.weight', 'image_encoder.blocks.8.norm2.bias', 'image_encoder.blocks.8.mlp.lin1.weight', 'image_encoder.blocks.8.mlp.lin1.bias', 'image_encoder.blocks.8.mlp.lin2.weight', 'image_encoder.blocks.8.mlp.lin2.bias', 'image_encoder.blocks.9.norm1.weight', 'image_encoder.blocks.9.norm1.bias', 'image_encoder.blocks.9.attn.rel_pos_h', 'image_encoder.blocks.9.attn.rel_pos_w', 'image_encoder.blocks.9.attn.qkv.weight', 'image_encoder.blocks.9.attn.qkv.bias', 'image_encoder.blocks.9.attn.proj.weight', 'image_encoder.blocks.9.attn.proj.bias', 'image_encoder.blocks.9.norm2.weight', 'image_encoder.blocks.9.norm2.bias', 'image_encoder.blocks.9.mlp.lin1.weight', 'image_encoder.blocks.9.mlp.lin1.bias', 'image_encoder.blocks.9.mlp.lin2.weight', 'image_encoder.blocks.9.mlp.lin2.bias', 'image_encoder.blocks.10.norm1.weight', 'image_encoder.blocks.10.norm1.bias', 'image_encoder.blocks.10.attn.rel_pos_h', 'image_encoder.blocks.10.attn.rel_pos_w', 'image_encoder.blocks.10.attn.qkv.weight', 'image_encoder.blocks.10.attn.qkv.bias', 'image_encoder.blocks.10.attn.proj.weight', 'image_encoder.blocks.10.attn.proj.bias', 'image_encoder.blocks.10.norm2.weight', 'image_encoder.blocks.10.norm2.bias', 'image_encoder.blocks.10.mlp.lin1.weight', 'image_encoder.blocks.10.mlp.lin1.bias', 'image_encoder.blocks.10.mlp.lin2.weight', 'image_encoder.blocks.10.mlp.lin2.bias', 'image_encoder.blocks.11.norm1.weight', 'image_encoder.blocks.11.norm1.bias', 'image_encoder.blocks.11.attn.rel_pos_h', 'image_encoder.blocks.11.attn.rel_pos_w', 'image_encoder.blocks.11.attn.qkv.weight', 'image_encoder.blocks.11.attn.qkv.bias', 'image_encoder.blocks.11.attn.proj.weight', 'image_encoder.blocks.11.attn.proj.bias', 'image_encoder.blocks.11.norm2.weight', 'image_encoder.blocks.11.norm2.bias', 'image_encoder.blocks.11.mlp.lin1.weight', 'image_encoder.blocks.11.mlp.lin1.bias', 'image_encoder.blocks.11.mlp.lin2.weight', 'image_encoder.blocks.11.mlp.lin2.bias', 'mask_decoder.transformer.layers.0.self_attn.q_proj.weight', 'mask_decoder.transformer.layers.0.self_attn.q_proj.bias', 'mask_decoder.transformer.layers.0.self_attn.k_proj.weight', 'mask_decoder.transformer.layers.0.self_attn.k_proj.bias', 'mask_decoder.transformer.layers.0.self_attn.v_proj.weight', 'mask_decoder.transformer.layers.0.self_attn.v_proj.bias', 'mask_decoder.transformer.layers.0.self_attn.out_proj.weight', 'mask_decoder.transformer.layers.0.self_attn.out_proj.bias', 'mask_decoder.transformer.layers.0.norm1.weight', 'mask_decoder.transformer.layers.0.norm1.bias', 'mask_decoder.transformer.layers.0.cross_attn_token_to_image.q_proj.weight', 'mask_decoder.transformer.layers.0.cross_attn_token_to_image.q_proj.bias', 'mask_decoder.transformer.layers.0.cross_attn_token_to_image.k_proj.weight', 'mask_decoder.transformer.layers.0.cross_attn_token_to_image.k_proj.bias', 'mask_decoder.transformer.layers.0.cross_attn_token_to_image.v_proj.weight', 'mask_decoder.transformer.layers.0.cross_attn_token_to_image.v_proj.bias', 'mask_decoder.transformer.layers.0.cross_attn_token_to_image.out_proj.weight', 'mask_decoder.transformer.layers.0.cross_attn_token_to_image.out_proj.bias', 'mask_decoder.transformer.layers.0.norm2.weight', 'mask_decoder.transformer.layers.0.norm2.bias', 'mask_decoder.transformer.layers.0.mlp.lin1.weight', 'mask_decoder.transformer.layers.0.mlp.lin1.bias', 'mask_decoder.transformer.layers.0.mlp.lin2.weight', 'mask_decoder.transformer.layers.0.mlp.lin2.bias', 'mask_decoder.transformer.layers.0.norm3.weight', 'mask_decoder.transformer.layers.0.norm3.bias', 'mask_decoder.transformer.layers.0.norm4.weight', 'mask_decoder.transformer.layers.0.norm4.bias', 'mask_decoder.transformer.layers.0.cross_attn_image_to_token.q_proj.weight', 'mask_decoder.transformer.layers.0.cross_attn_image_to_token.q_proj.bias', 'mask_decoder.transformer.layers.0.cross_attn_image_to_token.k_proj.weight', 'mask_decoder.transformer.layers.0.cross_attn_image_to_token.k_proj.bias', 'mask_decoder.transformer.layers.0.cross_attn_image_to_token.v_proj.weight', 'mask_decoder.transformer.layers.0.cross_attn_image_to_token.v_proj.bias', 'mask_decoder.transformer.layers.0.cross_attn_image_to_token.out_proj.weight', 'mask_decoder.transformer.layers.0.cross_attn_image_to_token.out_proj.bias', 'mask_decoder.transformer.layers.1.self_attn.q_proj.weight', 'mask_decoder.transformer.layers.1.self_attn.q_proj.bias', 'mask_decoder.transformer.layers.1.self_attn.k_proj.weight', 'mask_decoder.transformer.layers.1.self_attn.k_proj.bias', 'mask_decoder.transformer.layers.1.self_attn.v_proj.weight', 'mask_decoder.transformer.layers.1.self_attn.v_proj.bias', 'mask_decoder.transformer.layers.1.self_attn.out_proj.weight', 'mask_decoder.transformer.layers.1.self_attn.out_proj.bias', 'mask_decoder.transformer.layers.1.norm1.weight', 'mask_decoder.transformer.layers.1.norm1.bias', 'mask_decoder.transformer.layers.1.cross_attn_token_to_image.q_proj.weight', 'mask_decoder.transformer.layers.1.cross_attn_token_to_image.q_proj.bias', 'mask_decoder.transformer.layers.1.cross_attn_token_to_image.k_proj.weight', 'mask_decoder.transformer.layers.1.cross_attn_token_to_image.k_proj.bias', 'mask_decoder.transformer.layers.1.cross_attn_token_to_image.v_proj.weight', 'mask_decoder.transformer.layers.1.cross_attn_token_to_image.v_proj.bias', 'mask_decoder.transformer.layers.1.cross_attn_token_to_image.out_proj.weight', 'mask_decoder.transformer.layers.1.cross_attn_token_to_image.out_proj.bias', 'mask_decoder.transformer.layers.1.norm2.weight', 'mask_decoder.transformer.layers.1.norm2.bias', 'mask_decoder.transformer.layers.1.mlp.lin1.weight', 'mask_decoder.transformer.layers.1.mlp.lin1.bias', 'mask_decoder.transformer.layers.1.mlp.lin2.weight', 'mask_decoder.transformer.layers.1.mlp.lin2.bias', 'mask_decoder.transformer.layers.1.norm3.weight', 'mask_decoder.transformer.layers.1.norm3.bias', 'mask_decoder.transformer.layers.1.norm4.weight', 'mask_decoder.transformer.layers.1.norm4.bias', 'mask_decoder.transformer.layers.1.cross_attn_image_to_token.q_proj.weight', 'mask_decoder.transformer.layers.1.cross_attn_image_to_token.q_proj.bias', 'mask_decoder.transformer.layers.1.cross_attn_image_to_token.k_proj.weight', 'mask_decoder.transformer.layers.1.cross_attn_image_to_token.k_proj.bias', 'mask_decoder.transformer.layers.1.cross_attn_image_to_token.v_proj.weight', 'mask_decoder.transformer.layers.1.cross_attn_image_to_token.v_proj.bias', 'mask_decoder.transformer.layers.1.cross_attn_image_to_token.out_proj.weight', 'mask_decoder.transformer.layers.1.cross_attn_image_to_token.out_proj.bias', 'mask_decoder.transformer.final_attn_token_to_image.q_proj.weight', 'mask_decoder.transformer.final_attn_token_to_image.q_proj.bias', 'mask_decoder.transformer.final_attn_token_to_image.k_proj.weight', 'mask_decoder.transformer.final_attn_token_to_image.k_proj.bias', 'mask_decoder.transformer.final_attn_token_to_image.v_proj.weight', 'mask_decoder.transformer.final_attn_token_to_image.v_proj.bias', 'mask_decoder.transformer.final_attn_token_to_image.out_proj.weight', 'mask_decoder.transformer.final_attn_token_to_image.out_proj.bias', 'mask_decoder.transformer.norm_final_attn.weight', 'mask_decoder.transformer.norm_final_attn.bias', 'mask_decoder.output_upscaling.0.weight', 'mask_decoder.output_upscaling.0.bias', 'mask_decoder.output_upscaling.1.weight', 'mask_decoder.output_upscaling.1.bias', 'mask_decoder.output_upscaling.3.weight', 'mask_decoder.output_upscaling.3.bias', 'mask_decoder.output_hypernetworks_mlps.0.layers.0.weight', 'mask_decoder.output_hypernetworks_mlps.0.layers.0.bias', 'mask_decoder.output_hypernetworks_mlps.0.layers.1.weight', 'mask_decoder.output_hypernetworks_mlps.0.layers.1.bias', 'mask_decoder.output_hypernetworks_mlps.0.layers.2.weight', 'mask_decoder.output_hypernetworks_mlps.0.layers.2.bias', 'mask_decoder.output_hypernetworks_mlps.1.layers.0.weight', 'mask_decoder.output_hypernetworks_mlps.1.layers.0.bias', 'mask_decoder.output_hypernetworks_mlps.1.layers.1.weight', 'mask_decoder.output_hypernetworks_mlps.1.layers.1.bias', 'mask_decoder.output_hypernetworks_mlps.1.layers.2.weight', 'mask_decoder.output_hypernetworks_mlps.1.layers.2.bias', 'image_encoder.pos_embed'])
['patient_035', 'patient_083', 'patient_010', 'patient_086', 'patient_088']
['patient_057', 'patient_028', 'patient_087', 'patient_061', 'patient_032', 'patient_011', 'patient_078', 'patient_009', 'patient_068', 'patient_021', 'patient_079', 'patient_004', 'patient_089', 'patient_023', 'patient_070']
['patient_014', 'patient_060', 'patient_044', 'patient_036', 'patient_003', 'patient_100', 'patient_065', 'patient_013', 'patient_038', 'patient_093', 'patient_043', 'patient_082', 'patient_031', 'patient_005', 'patient_016']
dataset length: 104
dataset length: 258
dataset length: 296
output_experiment/original_g120_5
Train: [0][0/26]	loss 5.7792
Train: [0][10/26]	loss 1.6043
Train: [0][20/26]	loss 1.2502
Validating: Epoch:  0 Loss: 0.9453 IoU_pred: -0.0023
Train: [1][0/26]	loss 1.2452
Train: [1][10/26]	loss 1.3217
Train: [1][20/26]	loss 1.1772
Validating: Epoch:  1 Loss: 0.9700 IoU_pred: -0.0494
Train: [2][0/26]	loss 1.4552
Train: [2][10/26]	loss 1.1673
Train: [2][20/26]	loss 1.2317
Validating: Epoch:  2 Loss: 0.9421 IoU_pred: -0.0841
Train: [3][0/26]	loss 1.1697
Train: [3][10/26]	loss 1.1875
Train: [3][20/26]	loss 1.1911
Validating: Epoch:  3 Loss: 0.9376 IoU_pred: -0.1084
Train: [4][0/26]	loss 1.2078
Train: [4][10/26]	loss 1.1642
Train: [4][20/26]	loss 1.1817
Validating: Epoch:  4 Loss: 0.9301 IoU_pred: 0.0187
Train: [5][0/26]	loss 1.2015
Train: [5][10/26]	loss 1.1830
Train: [5][20/26]	loss 1.3978
Validating: Epoch:  5 Loss: 0.9176 IoU_pred: -0.0384
Train: [6][0/26]	loss 1.3698
Train: [6][10/26]	loss 1.2624
Train: [6][20/26]	loss 1.3506
Validating: Epoch:  6 Loss: 0.9256 IoU_pred: 0.0406
Train: [7][0/26]	loss 1.2749
Train: [7][10/26]	loss 1.2151
Train: [7][20/26]	loss 1.1542
Validating: Epoch:  7 Loss: 0.8975 IoU_pred: 0.0468
Train: [8][0/26]	loss 1.1926
Train: [8][10/26]	loss 1.2339
Train: [8][20/26]	loss 1.1099
Validating: Epoch:  8 Loss: 0.9050 IoU_pred: 0.0069
Train: [9][0/26]	loss 1.1272
Train: [9][10/26]	loss 1.0956
Train: [9][20/26]	loss 1.1350
Validating: Epoch:  9 Loss: 0.8900 IoU_pred: 0.0900
Train: [10][0/26]	loss 1.1259
Train: [10][10/26]	loss 1.1153
Train: [10][20/26]	loss 1.1339
Validating: Epoch: 10 Loss: 0.8630 IoU_pred: 0.0512
Train: [11][0/26]	loss 1.1779
Train: [11][10/26]	loss 1.5018
Train: [11][20/26]	loss 1.0792
Validating: Epoch: 11 Loss: 0.9498 IoU_pred: 0.0720
Train: [12][0/26]	loss 1.2404
Train: [12][10/26]	loss 1.0830
Train: [12][20/26]	loss 1.2127
Validating: Epoch: 12 Loss: 0.9465 IoU_pred: 0.1548
Train: [13][0/26]	loss 1.2251
Train: [13][10/26]	loss 1.2068
Train: [13][20/26]	loss 1.2709
Validating: Epoch: 13 Loss: 0.9782 IoU_pred: 0.1288
Train: [14][0/26]	loss 1.1885
Train: [14][10/26]	loss 1.1866
Train: [14][20/26]	loss 1.0966
Validating: Epoch: 14 Loss: 0.9424 IoU_pred: 0.1276
Train: [15][0/26]	loss 1.1264
Train: [15][10/26]	loss 1.1300
Train: [15][20/26]	loss 1.3486
Validating: Epoch: 15 Loss: 0.9019 IoU_pred: 0.1745
Train: [16][0/26]	loss 1.1667
Train: [16][10/26]	loss 1.1157
Train: [16][20/26]	loss 0.9949
Validating: Epoch: 16 Loss: 0.8476 IoU_pred: 0.1561
Train: [17][0/26]	loss 1.0519
Train: [17][10/26]	loss 1.0832
Train: [17][20/26]	loss 1.1155
Validating: Epoch: 17 Loss: 0.8594 IoU_pred: 0.1474
Train: [18][0/26]	loss 1.0665
Train: [18][10/26]	loss 1.1132
Train: [18][20/26]	loss 1.2505
Validating: Epoch: 18 Loss: 0.8944 IoU_pred: 0.1659
Train: [19][0/26]	loss 1.0324
Train: [19][10/26]	loss 1.0540
Train: [19][20/26]	loss 1.0882
Validating: Epoch: 19 Loss: 0.8682 IoU_pred: 0.1640
Train: [20][0/26]	loss 1.1682
Train: [20][10/26]	loss 1.0432
Train: [20][20/26]	loss 1.0156
Validating: Epoch: 20 Loss: 0.8214 IoU_pred: 0.2072
Train: [21][0/26]	loss 1.2994
Train: [21][10/26]	loss 1.1298
Train: [21][20/26]	loss 1.0732
Validating: Epoch: 21 Loss: 0.7744 IoU_pred: 0.1800
Train: [22][0/26]	loss 0.9467
Train: [22][10/26]	loss 0.8929
Train: [22][20/26]	loss 0.9345
Validating: Epoch: 22 Loss: 0.8570 IoU_pred: 0.2726
Train: [23][0/26]	loss 0.9957
Train: [23][10/26]	loss 1.0634
Train: [23][20/26]	loss 0.9558
Validating: Epoch: 23 Loss: 0.7947 IoU_pred: 0.2587
Train: [24][0/26]	loss 0.9105
Train: [24][10/26]	loss 1.0510
Train: [24][20/26]	loss 1.1181
Validating: Epoch: 24 Loss: 0.8006 IoU_pred: 0.2437
Train: [25][0/26]	loss 1.0002
Train: [25][10/26]	loss 0.8692
Train: [25][20/26]	loss 0.9363
Validating: Epoch: 25 Loss: 0.8511 IoU_pred: 0.2301
Train: [26][0/26]	loss 1.1330
Train: [26][10/26]	loss 1.0158
Train: [26][20/26]	loss 0.8686
Validating: Epoch: 26 Loss: 0.7671 IoU_pred: 0.1826
Train: [27][0/26]	loss 0.7786
Train: [27][10/26]	loss 0.9208
Train: [27][20/26]	loss 0.8460
Validating: Epoch: 27 Loss: 0.7188 IoU_pred: 0.2723
Train: [28][0/26]	loss 0.9565
Train: [28][10/26]	loss 0.9075
Train: [28][20/26]	loss 0.8758
Validating: Epoch: 28 Loss: 0.7599 IoU_pred: 0.2454
Train: [29][0/26]	loss 0.8075
Train: [29][10/26]	loss 0.7160
Train: [29][20/26]	loss 0.7650
Validating: Epoch: 29 Loss: 0.7409 IoU_pred: 0.2378
Train: [30][0/26]	loss 0.9164
Train: [30][10/26]	loss 0.8916
Train: [30][20/26]	loss 0.8874
Validating: Epoch: 30 Loss: 0.7121 IoU_pred: 0.1712
Train: [31][0/26]	loss 0.8155
Train: [31][10/26]	loss 0.8042
Train: [31][20/26]	loss 0.8366
Validating: Epoch: 31 Loss: 0.7290 IoU_pred: 0.1696
Train: [32][0/26]	loss 1.0882
Train: [32][10/26]	loss 0.8215
Train: [32][20/26]	loss 0.8917
Validating: Epoch: 32 Loss: 0.6934 IoU_pred: 0.2053
Train: [33][0/26]	loss 0.7942
Train: [33][10/26]	loss 0.9120
Train: [33][20/26]	loss 0.7344
Validating: Epoch: 33 Loss: 0.7072 IoU_pred: 0.1735
Train: [34][0/26]	loss 0.7107
Train: [34][10/26]	loss 0.8194
Train: [34][20/26]	loss 0.6431
Validating: Epoch: 34 Loss: 0.6961 IoU_pred: 0.1993
Train: [35][0/26]	loss 0.6857
Train: [35][10/26]	loss 0.7066
Train: [35][20/26]	loss 0.7956
Validating: Epoch: 35 Loss: 0.6809 IoU_pred: 0.1762
Train: [36][0/26]	loss 0.7250
Train: [36][10/26]	loss 0.8018
Train: [36][20/26]	loss 1.0226
Validating: Epoch: 36 Loss: 0.7330 IoU_pred: 0.2445
Train: [37][0/26]	loss 0.9171
Train: [37][10/26]	loss 0.7486
Train: [37][20/26]	loss 0.8319
Validating: Epoch: 37 Loss: 0.7013 IoU_pred: 0.2132
Train: [38][0/26]	loss 0.6433
Train: [38][10/26]	loss 0.6613
Train: [38][20/26]	loss 0.6688
Validating: Epoch: 38 Loss: 0.6720 IoU_pred: 0.2297
Train: [39][0/26]	loss 0.6334
Train: [39][10/26]	loss 0.7859
Train: [39][20/26]	loss 0.6591
Validating: Epoch: 39 Loss: 0.6493 IoU_pred: 0.2128
Train: [40][0/26]	loss 0.5162
Train: [40][10/26]	loss 0.6828
Train: [40][20/26]	loss 0.5967
Validating: Epoch: 40 Loss: 0.6514 IoU_pred: 0.2066
Train: [41][0/26]	loss 0.6119
Train: [41][10/26]	loss 0.7318
Train: [41][20/26]	loss 0.5849
Validating: Epoch: 41 Loss: 0.6339 IoU_pred: 0.1951
Train: [42][0/26]	loss 0.5939
Train: [42][10/26]	loss 0.4736
Train: [42][20/26]	loss 0.5682
Validating: Epoch: 42 Loss: 0.6168 IoU_pred: 0.1967
Train: [43][0/26]	loss 0.7521
Train: [43][10/26]	loss 0.5363
Train: [43][20/26]	loss 0.6960
Validating: Epoch: 43 Loss: 0.6127 IoU_pred: 0.2033
Train: [44][0/26]	loss 0.6588
Train: [44][10/26]	loss 0.4300
Train: [44][20/26]	loss 0.5682
Validating: Epoch: 44 Loss: 0.6317 IoU_pred: 0.2324
Train: [45][0/26]	loss 0.6753
Train: [45][10/26]	loss 0.5090
Train: [45][20/26]	loss 0.5251
Validating: Epoch: 45 Loss: 0.5968 IoU_pred: 0.2043
Train: [46][0/26]	loss 0.8603
Train: [46][10/26]	loss 0.8210
Train: [46][20/26]	loss 0.8142
Validating: Epoch: 46 Loss: 0.5757 IoU_pred: 0.2065
Train: [47][0/26]	loss 0.6173
Train: [47][10/26]	loss 0.5319
Train: [47][20/26]	loss 0.4933
Validating: Epoch: 47 Loss: 0.6676 IoU_pred: 0.2884
Train: [48][0/26]	loss 0.4487
Train: [48][10/26]	loss 0.7264
Train: [48][20/26]	loss 0.6636
Validating: Epoch: 48 Loss: 0.6287 IoU_pred: 0.2632
Train: [49][0/26]	loss 0.4528
Train: [49][10/26]	loss 0.5388
Train: [49][20/26]	loss 0.7629
Validating: Epoch: 49 Loss: 0.5784 IoU_pred: 0.2391
Train: [50][0/26]	loss 0.5936
Train: [50][10/26]	loss 0.5127
Train: [50][20/26]	loss 0.3242
Validating: Epoch: 50 Loss: 0.5239 IoU_pred: 0.2125
Train: [51][0/26]	loss 0.3397
Train: [51][10/26]	loss 0.4622
Train: [51][20/26]	loss 0.4124
Validating: Epoch: 51 Loss: 0.4908 IoU_pred: 0.2073
Train: [52][0/26]	loss 0.2991
Train: [52][10/26]	loss 0.5345
Train: [52][20/26]	loss 0.6414
Validating: Epoch: 52 Loss: 0.4708 IoU_pred: 0.2311
Train: [53][0/26]	loss 0.3456
Train: [53][10/26]	loss 0.5619
Train: [53][20/26]	loss 0.4941
Validating: Epoch: 53 Loss: 0.4580 IoU_pred: 0.2616
Train: [54][0/26]	loss 0.3823
Train: [54][10/26]	loss 0.8582
Train: [54][20/26]	loss 0.4403
Validating: Epoch: 54 Loss: 0.5271 IoU_pred: 0.2877
Train: [55][0/26]	loss 0.4780
Train: [55][10/26]	loss 0.2776
Train: [55][20/26]	loss 0.3980
Validating: Epoch: 55 Loss: 0.4551 IoU_pred: 0.2557
Train: [56][0/26]	loss 0.5381
Train: [56][10/26]	loss 0.2422
Train: [56][20/26]	loss 0.2994
Validating: Epoch: 56 Loss: 0.4496 IoU_pred: 0.2350
Train: [57][0/26]	loss 0.3828
Train: [57][10/26]	loss 0.2743
Train: [57][20/26]	loss 0.2649
Validating: Epoch: 57 Loss: 0.4693 IoU_pred: 0.2634
Train: [58][0/26]	loss 0.2898
Train: [58][10/26]	loss 0.2318
Train: [58][20/26]	loss 0.5047
Validating: Epoch: 58 Loss: 0.4156 IoU_pred: 0.3853
Train: [59][0/26]	loss 0.3214
Train: [59][10/26]	loss 0.2665
Train: [59][20/26]	loss 0.2419
Validating: Epoch: 59 Loss: 0.3987 IoU_pred: 0.2364
Train: [60][0/26]	loss 0.5393
Train: [60][10/26]	loss 0.2939
Train: [60][20/26]	loss 0.3922
Validating: Epoch: 60 Loss: 0.4355 IoU_pred: 0.3285
Train: [61][0/26]	loss 0.2330
Train: [61][10/26]	loss 0.2542
Train: [61][20/26]	loss 0.3336
Validating: Epoch: 61 Loss: 0.4645 IoU_pred: 0.2684
Train: [62][0/26]	loss 0.5712
Train: [62][10/26]	loss 0.3088
Train: [62][20/26]	loss 0.2954
Validating: Epoch: 62 Loss: 0.4278 IoU_pred: 0.3778
Train: [63][0/26]	loss 0.2557
Train: [63][10/26]	loss 0.2272
Train: [63][20/26]	loss 0.3871
Validating: Epoch: 63 Loss: 0.3950 IoU_pred: 0.3416
Train: [64][0/26]	loss 0.3254
Train: [64][10/26]	loss 0.2359
Train: [64][20/26]	loss 0.2540
Validating: Epoch: 64 Loss: 0.3681 IoU_pred: 0.2583
Train: [65][0/26]	loss 0.2495
Train: [65][10/26]	loss 0.2732
Train: [65][20/26]	loss 0.2277
Validating: Epoch: 65 Loss: 0.3609 IoU_pred: 0.2937
Train: [66][0/26]	loss 0.1786
Train: [66][10/26]	loss 0.1915
Train: [66][20/26]	loss 0.2027
Validating: Epoch: 66 Loss: 0.3695 IoU_pred: 0.2002
Train: [67][0/26]	loss 0.1653
Train: [67][10/26]	loss 0.1833
Train: [67][20/26]	loss 0.3383
Validating: Epoch: 67 Loss: 0.3596 IoU_pred: 0.3274
Train: [68][0/26]	loss 0.2714
Train: [68][10/26]	loss 0.1954
Train: [68][20/26]	loss 0.2155
Validating: Epoch: 68 Loss: 0.3777 IoU_pred: 0.3491
Train: [69][0/26]	loss 0.4419
Train: [69][10/26]	loss 0.2875
Train: [69][20/26]	loss 0.5548
Validating: Epoch: 69 Loss: 0.4004 IoU_pred: 0.3251
Train: [70][0/26]	loss 0.3115
Train: [70][10/26]	loss 0.5159
Train: [70][20/26]	loss 0.2022
Validating: Epoch: 70 Loss: 0.3365 IoU_pred: 0.3176
Train: [71][0/26]	loss 0.2180
Train: [71][10/26]	loss 0.2058
Train: [71][20/26]	loss 0.1479
Validating: Epoch: 71 Loss: 0.3304 IoU_pred: 0.3577
Train: [72][0/26]	loss 0.1691
Train: [72][10/26]	loss 0.2568
Train: [72][20/26]	loss 0.1248
Validating: Epoch: 72 Loss: 0.3351 IoU_pred: 0.3653
Train: [73][0/26]	loss 0.1474
Train: [73][10/26]	loss 0.3212
Train: [73][20/26]	loss 0.3337
Validating: Epoch: 73 Loss: 0.3177 IoU_pred: 0.3744
Train: [74][0/26]	loss 0.2368
Train: [74][10/26]	loss 0.1509
Train: [74][20/26]	loss 0.2182
Validating: Epoch: 74 Loss: 0.3319 IoU_pred: 0.3179
Train: [75][0/26]	loss 0.1453
Train: [75][10/26]	loss 0.1259
Train: [75][20/26]	loss 0.1969
Validating: Epoch: 75 Loss: 0.3060 IoU_pred: 0.3781
Train: [76][0/26]	loss 0.1297
Train: [76][10/26]	loss 0.3634
Train: [76][20/26]	loss 0.1208
Validating: Epoch: 76 Loss: 0.3001 IoU_pred: 0.3647
Train: [77][0/26]	loss 0.4106
Train: [77][10/26]	loss 0.2343
Train: [77][20/26]	loss 0.1464
Validating: Epoch: 77 Loss: 0.3006 IoU_pred: 0.3780
Train: [78][0/26]	loss 0.2118
Train: [78][10/26]	loss 0.1765
Train: [78][20/26]	loss 0.1184
Validating: Epoch: 78 Loss: 0.3045 IoU_pred: 0.3765
Train: [79][0/26]	loss 0.2911
Train: [79][10/26]	loss 0.1809
Train: [79][20/26]	loss 0.4157
Validating: Epoch: 79 Loss: 0.3269 IoU_pred: 0.3419
Train: [80][0/26]	loss 0.1566
Train: [80][10/26]	loss 0.1322
Train: [80][20/26]	loss 0.2723
Validating: Epoch: 80 Loss: 0.3063 IoU_pred: 0.3596
Train: [81][0/26]	loss 0.1406
Train: [81][10/26]	loss 0.3337
Train: [81][20/26]	loss 0.1294
Validating: Epoch: 81 Loss: 0.3129 IoU_pred: 0.2777
Train: [82][0/26]	loss 0.5932
Train: [82][10/26]	loss 0.1240
Train: [82][20/26]	loss 0.1525
Validating: Epoch: 82 Loss: 0.3075 IoU_pred: 0.3494
Train: [83][0/26]	loss 0.3069
Train: [83][10/26]	loss 0.1679
Train: [83][20/26]	loss 0.2076
Validating: Epoch: 83 Loss: 0.3282 IoU_pred: 0.3483
Train: [84][0/26]	loss 0.1954
Train: [84][10/26]	loss 0.2311
Train: [84][20/26]	loss 0.1358
Validating: Epoch: 84 Loss: 0.3236 IoU_pred: 0.3722
Train: [85][0/26]	loss 0.2400
Train: [85][10/26]	loss 0.1579
Train: [85][20/26]	loss 0.1631
Validating: Epoch: 85 Loss: 0.3254 IoU_pred: 0.3581
Train: [86][0/26]	loss 0.2357
Train: [86][10/26]	loss 0.4612
Train: [86][20/26]	loss 0.3010
Validating: Epoch: 86 Loss: 0.3077 IoU_pred: 0.3043
Train: [87][0/26]	loss 0.3274
Train: [87][10/26]	loss 0.1985
Train: [87][20/26]	loss 0.1793
Validating: Epoch: 87 Loss: 0.3205 IoU_pred: 0.3706
Train: [88][0/26]	loss 0.2080
Train: [88][10/26]	loss 0.1440
Train: [88][20/26]	loss 0.2008
Validating: Epoch: 88 Loss: 0.3261 IoU_pred: 0.3741
Train: [89][0/26]	loss 0.2537
Train: [89][10/26]	loss 0.3453
Train: [89][20/26]	loss 0.2581
Validating: Epoch: 89 Loss: 0.3260 IoU_pred: 0.3580
Train: [90][0/26]	loss 0.2085
Train: [90][10/26]	loss 0.2808
Train: [90][20/26]	loss 0.3325
Validating: Epoch: 90 Loss: 0.3249 IoU_pred: 0.3746
Train: [91][0/26]	loss 0.1786
Train: [91][10/26]	loss 0.1621
Train: [91][20/26]	loss 0.3397
Validating: Epoch: 91 Loss: 0.3332 IoU_pred: 0.3475
Train: [92][0/26]	loss 0.2244
Train: [92][10/26]	loss 0.1801
Train: [92][20/26]	loss 0.1947
Validating: Epoch: 92 Loss: 0.3570 IoU_pred: 0.3204
Train: [93][0/26]	loss 0.1501
Train: [93][10/26]	loss 0.1260
Train: [93][20/26]	loss 0.5790
Validating: Epoch: 93 Loss: 0.3545 IoU_pred: 0.3655
Train: [94][0/26]	loss 0.1468
Train: [94][10/26]	loss 0.2337
Train: [94][20/26]	loss 0.1409
Validating: Epoch: 94 Loss: 0.3427 IoU_pred: 0.3840
Train: [95][0/26]	loss 0.1147
Train: [95][10/26]	loss 0.3267
Train: [95][20/26]	loss 0.1788
Validating: Epoch: 95 Loss: 0.3742 IoU_pred: 0.3878
Train: [96][0/26]	loss 0.2543
Train: [96][10/26]	loss 0.1815
Train: [96][20/26]	loss 0.1365
Validating: Epoch: 96 Loss: 0.3482 IoU_pred: 0.3645
Train: [97][0/26]	loss 0.4375
Train: [97][10/26]	loss 0.3889
Train: [97][20/26]	loss 0.1505
Validating: Epoch: 97 Loss: 0.3690 IoU_pred: 0.3789
Train: [98][0/26]	loss 0.2410
Train: [98][10/26]	loss 0.2168
Train: [98][20/26]	loss 0.3003
Validating: Epoch: 98 Loss: 0.3010 IoU_pred: 0.3057
Train: [99][0/26]	loss 0.1348
Train: [99][10/26]	loss 0.2060
Train: [99][20/26]	loss 0.1572
Validating: Epoch: 99 Loss: 0.3716 IoU_pred: 0.3324
Train: [100][0/26]	loss 0.1701
Train: [100][10/26]	loss 0.3204
Train: [100][20/26]	loss 0.1459
Validating: Epoch: 100 Loss: 0.3648 IoU_pred: 0.3641
Train: [101][0/26]	loss 0.3413
Train: [101][10/26]	loss 0.3258
Train: [101][20/26]	loss 0.1130
Validating: Epoch: 101 Loss: 0.3142 IoU_pred: 0.3192
Train: [102][0/26]	loss 0.4240
Train: [102][10/26]	loss 0.1882
Train: [102][20/26]	loss 0.1727
Validating: Epoch: 102 Loss: 0.3246 IoU_pred: 0.2917
Train: [103][0/26]	loss 0.2040
Train: [103][10/26]	loss 0.1522
Train: [103][20/26]	loss 0.1395
Validating: Epoch: 103 Loss: 0.3121 IoU_pred: 0.3538
Train: [104][0/26]	loss 0.2449
Train: [104][10/26]	loss 0.2718
Train: [104][20/26]	loss 0.3321
Validating: Epoch: 104 Loss: 0.3316 IoU_pred: 0.3306
Train: [105][0/26]	loss 0.2140
Train: [105][10/26]	loss 0.2089
Train: [105][20/26]	loss 0.2034
Validating: Epoch: 105 Loss: 0.3960 IoU_pred: 0.3180
Train: [106][0/26]	loss 0.1339
Train: [106][10/26]	loss 0.1289
Train: [106][20/26]	loss 0.1302
Validating: Epoch: 106 Loss: 0.3801 IoU_pred: 0.3135
Train: [107][0/26]	loss 0.1310
Train: [107][10/26]	loss 0.3324
Train: [107][20/26]	loss 0.2218
Validating: Epoch: 107 Loss: 0.3896 IoU_pred: 0.3287
Train: [108][0/26]	loss 0.2320
Train: [108][10/26]	loss 0.1523
Train: [108][20/26]	loss 0.1444
Validating: Epoch: 108 Loss: 0.3782 IoU_pred: 0.3444
Train: [109][0/26]	loss 0.1740
Train: [109][10/26]	loss 0.1572
Train: [109][20/26]	loss 0.1719
Validating: Epoch: 109 Loss: 0.3259 IoU_pred: 0.3066
Train: [110][0/26]	loss 0.3649
Train: [110][10/26]	loss 0.1425
Train: [110][20/26]	loss 0.2405
Validating: Epoch: 110 Loss: 0.3335 IoU_pred: 0.3396
Train: [111][0/26]	loss 0.1227
Train: [111][10/26]	loss 0.1529
Train: [111][20/26]	loss 0.1392
Validating: Epoch: 111 Loss: 0.3136 IoU_pred: 0.3337
Train: [112][0/26]	loss 0.1066
Train: [112][10/26]	loss 0.1926
Train: [112][20/26]	loss 0.1759
Validating: Epoch: 112 Loss: 0.3382 IoU_pred: 0.4220
Train: [113][0/26]	loss 0.1823
Train: [113][10/26]	loss 0.2487
Train: [113][20/26]	loss 0.3186
Validating: Epoch: 113 Loss: 0.3442 IoU_pred: 0.3812
Train: [114][0/26]	loss 0.1346
Train: [114][10/26]	loss 0.3091
Train: [114][20/26]	loss 0.5001
Validating: Epoch: 114 Loss: 0.3306 IoU_pred: 0.3956
Train: [115][0/26]	loss 0.2727
Train: [115][10/26]	loss 0.3111
Train: [115][20/26]	loss 0.1308
Validating: Epoch: 115 Loss: 0.3212 IoU_pred: 0.3072
Train: [116][0/26]	loss 0.1828
Train: [116][10/26]	loss 0.2647
Train: [116][20/26]	loss 0.1830
Validating: Epoch: 116 Loss: 0.3506 IoU_pred: 0.3856
Train: [117][0/26]	loss 0.2266
Train: [117][10/26]	loss 0.3500
Train: [117][20/26]	loss 0.2022
Validating: Epoch: 117 Loss: 0.3280 IoU_pred: 0.3480
Train: [118][0/26]	loss 0.1709
Train: [118][10/26]	loss 0.0869
Train: [118][20/26]	loss 0.1441
Validating: Epoch: 118 Loss: 0.3127 IoU_pred: 0.3171
Train: [119][0/26]	loss 0.3282
Train: [119][10/26]	loss 0.1957
Train: [119][20/26]	loss 0.4188
Validating: Epoch: 119 Loss: 0.3275 IoU_pred: 0.3133
Test
dataset length: 20
(20, 224, 224) (20, 224, 224)
finish saving file: patient_014
dataset length: 18
(18, 224, 224) (18, 224, 224)
finish saving file: patient_060
dataset length: 18
(18, 224, 224) (18, 224, 224)
finish saving file: patient_044
dataset length: 16
(16, 224, 224) (16, 224, 224)
finish saving file: patient_036
dataset length: 20
(20, 224, 224) (20, 224, 224)
finish saving file: patient_003
dataset length: 16
(16, 224, 224) (16, 224, 224)
finish saving file: patient_100
dataset length: 16
(16, 224, 224) (16, 224, 224)
finish saving file: patient_065
dataset length: 20
(20, 224, 224) (20, 224, 224)
finish saving file: patient_013
dataset length: 16
(16, 224, 224) (16, 224, 224)
finish saving file: patient_038
dataset length: 20
(20, 224, 224) (20, 224, 224)
finish saving file: patient_093
dataset length: 24
(24, 224, 224) (24, 224, 224)
finish saving file: patient_043
dataset length: 32
(32, 224, 224) (32, 224, 224)
finish saving file: patient_082
dataset length: 20
(20, 224, 224) (20, 224, 224)
finish saving file: patient_031
dataset length: 20
(20, 224, 224) (20, 224, 224)
finish saving file: patient_005
dataset length: 20
/home/kl321/miniconda3/envs/medsam/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.
  return _methods._mean(a, axis=axis, dtype=dtype,
/home/kl321/miniconda3/envs/medsam/lib/python3.10/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)
(20, 224, 224) (20, 224, 224)
finish saving file: patient_016
patient_003.nii
patient_003.nii
patient_005.nii
patient_005.nii
patient_013.nii
patient_013.nii
patient_014.nii
patient_014.nii
patient_016.nii
patient_016.nii
patient_031.nii
patient_031.nii
patient_036.nii
patient_036.nii
patient_038.nii
patient_038.nii
patient_043.nii
patient_043.nii
patient_044.nii
patient_044.nii
patient_060.nii
patient_060.nii
patient_065.nii
patient_065.nii
patient_082.nii
patient_082.nii
patient_093.nii
patient_093.nii
patient_100.nii
patient_100.nii
done
********************
patient_003.nii
********************
patient_003.nii
Dice_rv: 0.7059
Dice_myo: 0.7008
Dice_lv: 0.9039
********************
********************
patient_005.nii
********************
patient_005.nii
Dice_rv: 0.4498
Dice_myo: 0.7173
Dice_lv: 0.9266
********************
********************
patient_013.nii
********************
patient_013.nii
Dice_rv: 0.5609
Dice_myo: 0.7666
Dice_lv: 0.9182
********************
********************
patient_014.nii
********************
patient_014.nii
Dice_rv: 0.7737
Dice_myo: 0.6897
Dice_lv: 0.8966
********************
********************
patient_016.nii
********************
patient_016.nii
Dice_rv: 0.6079
Dice_myo: 0.6205
Dice_lv: 0.9186
********************
********************
patient_031.nii
********************
patient_031.nii
Dice_rv: 0.5863
Dice_myo: 0.7193
Dice_lv: 0.8714
********************
********************
patient_036.nii
********************
patient_036.nii
Dice_rv: 0.5676
Dice_myo: 0.8071
Dice_lv: 0.8794
********************
********************
patient_038.nii
********************
patient_038.nii
Dice_rv: 0.3846
Dice_myo: 0.7260
Dice_lv: 0.8801
********************
********************
patient_043.nii
********************
patient_043.nii
Dice_rv: 0.6206
Dice_myo: 0.6870
Dice_lv: 0.8164
********************
********************
patient_044.nii
********************
patient_044.nii
Dice_rv: 0.3504
Dice_myo: 0.4724
Dice_lv: 0.7881
********************
********************
patient_060.nii
********************
patient_060.nii
Dice_rv: 0.2963
Dice_myo: 0.6437
Dice_lv: 0.4243
********************
********************
patient_065.nii
********************
patient_065.nii
Dice_rv: 0.5325
Dice_myo: 0.4600
Dice_lv: 0.7491
********************
********************
patient_082.nii
********************
patient_082.nii
Dice_rv: 0.7863
Dice_myo: 0.6926
Dice_lv: 0.8717
********************
********************
patient_093.nii
********************
patient_093.nii
Dice_rv: 0.6829
Dice_myo: 0.5876
Dice_lv: 0.8619
********************
********************
patient_100.nii
********************
patient_100.nii
Dice_rv: 0.7825
Dice_myo: 0.6438
Dice_lv: 0.8992
********************
********************
Mean_Dice
Dice_rv0.5792219359705642
Dice_myo0.6622847371537246
Dice_lv0.8403692669952231
Mean_HD
********************
avg_hd:nan
DSC:0.6939586467065039
HD:nan
