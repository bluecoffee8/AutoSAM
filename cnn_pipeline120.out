/home/kl321/AutoSAM/scripts/main_feat_seg.py:115: UserWarning: You have chosen a specific GPU. This will completely disable data parallelism.
  warnings.warn('You have chosen a specific GPU. This will completely '
Use GPU: 0 for training
loaded keys: ['image_encoder.neck.0.weight', 'image_encoder.neck.1.weight', 'image_encoder.neck.1.bias', 'image_encoder.neck.2.weight', 'image_encoder.neck.3.weight', 'image_encoder.neck.3.bias', 'image_encoder.patch_embed.proj.weight', 'image_encoder.patch_embed.proj.bias', 'image_encoder.blocks.0.norm1.weight', 'image_encoder.blocks.0.norm1.bias', 'image_encoder.blocks.0.attn.rel_pos_h', 'image_encoder.blocks.0.attn.rel_pos_w', 'image_encoder.blocks.0.attn.qkv.weight', 'image_encoder.blocks.0.attn.qkv.bias', 'image_encoder.blocks.0.attn.proj.weight', 'image_encoder.blocks.0.attn.proj.bias', 'image_encoder.blocks.0.norm2.weight', 'image_encoder.blocks.0.norm2.bias', 'image_encoder.blocks.0.mlp.lin1.weight', 'image_encoder.blocks.0.mlp.lin1.bias', 'image_encoder.blocks.0.mlp.lin2.weight', 'image_encoder.blocks.0.mlp.lin2.bias', 'image_encoder.blocks.1.norm1.weight', 'image_encoder.blocks.1.norm1.bias', 'image_encoder.blocks.1.attn.rel_pos_h', 'image_encoder.blocks.1.attn.rel_pos_w', 'image_encoder.blocks.1.attn.qkv.weight', 'image_encoder.blocks.1.attn.qkv.bias', 'image_encoder.blocks.1.attn.proj.weight', 'image_encoder.blocks.1.attn.proj.bias', 'image_encoder.blocks.1.norm2.weight', 'image_encoder.blocks.1.norm2.bias', 'image_encoder.blocks.1.mlp.lin1.weight', 'image_encoder.blocks.1.mlp.lin1.bias', 'image_encoder.blocks.1.mlp.lin2.weight', 'image_encoder.blocks.1.mlp.lin2.bias', 'image_encoder.blocks.2.norm1.weight', 'image_encoder.blocks.2.norm1.bias', 'image_encoder.blocks.2.attn.rel_pos_h', 'image_encoder.blocks.2.attn.rel_pos_w', 'image_encoder.blocks.2.attn.qkv.weight', 'image_encoder.blocks.2.attn.qkv.bias', 'image_encoder.blocks.2.attn.proj.weight', 'image_encoder.blocks.2.attn.proj.bias', 'image_encoder.blocks.2.norm2.weight', 'image_encoder.blocks.2.norm2.bias', 'image_encoder.blocks.2.mlp.lin1.weight', 'image_encoder.blocks.2.mlp.lin1.bias', 'image_encoder.blocks.2.mlp.lin2.weight', 'image_encoder.blocks.2.mlp.lin2.bias', 'image_encoder.blocks.3.norm1.weight', 'image_encoder.blocks.3.norm1.bias', 'image_encoder.blocks.3.attn.rel_pos_h', 'image_encoder.blocks.3.attn.rel_pos_w', 'image_encoder.blocks.3.attn.qkv.weight', 'image_encoder.blocks.3.attn.qkv.bias', 'image_encoder.blocks.3.attn.proj.weight', 'image_encoder.blocks.3.attn.proj.bias', 'image_encoder.blocks.3.norm2.weight', 'image_encoder.blocks.3.norm2.bias', 'image_encoder.blocks.3.mlp.lin1.weight', 'image_encoder.blocks.3.mlp.lin1.bias', 'image_encoder.blocks.3.mlp.lin2.weight', 'image_encoder.blocks.3.mlp.lin2.bias', 'image_encoder.blocks.4.norm1.weight', 'image_encoder.blocks.4.norm1.bias', 'image_encoder.blocks.4.attn.rel_pos_h', 'image_encoder.blocks.4.attn.rel_pos_w', 'image_encoder.blocks.4.attn.qkv.weight', 'image_encoder.blocks.4.attn.qkv.bias', 'image_encoder.blocks.4.attn.proj.weight', 'image_encoder.blocks.4.attn.proj.bias', 'image_encoder.blocks.4.norm2.weight', 'image_encoder.blocks.4.norm2.bias', 'image_encoder.blocks.4.mlp.lin1.weight', 'image_encoder.blocks.4.mlp.lin1.bias', 'image_encoder.blocks.4.mlp.lin2.weight', 'image_encoder.blocks.4.mlp.lin2.bias', 'image_encoder.blocks.5.norm1.weight', 'image_encoder.blocks.5.norm1.bias', 'image_encoder.blocks.5.attn.rel_pos_h', 'image_encoder.blocks.5.attn.rel_pos_w', 'image_encoder.blocks.5.attn.qkv.weight', 'image_encoder.blocks.5.attn.qkv.bias', 'image_encoder.blocks.5.attn.proj.weight', 'image_encoder.blocks.5.attn.proj.bias', 'image_encoder.blocks.5.norm2.weight', 'image_encoder.blocks.5.norm2.bias', 'image_encoder.blocks.5.mlp.lin1.weight', 'image_encoder.blocks.5.mlp.lin1.bias', 'image_encoder.blocks.5.mlp.lin2.weight', 'image_encoder.blocks.5.mlp.lin2.bias', 'image_encoder.blocks.6.norm1.weight', 'image_encoder.blocks.6.norm1.bias', 'image_encoder.blocks.6.attn.rel_pos_h', 'image_encoder.blocks.6.attn.rel_pos_w', 'image_encoder.blocks.6.attn.qkv.weight', 'image_encoder.blocks.6.attn.qkv.bias', 'image_encoder.blocks.6.attn.proj.weight', 'image_encoder.blocks.6.attn.proj.bias', 'image_encoder.blocks.6.norm2.weight', 'image_encoder.blocks.6.norm2.bias', 'image_encoder.blocks.6.mlp.lin1.weight', 'image_encoder.blocks.6.mlp.lin1.bias', 'image_encoder.blocks.6.mlp.lin2.weight', 'image_encoder.blocks.6.mlp.lin2.bias', 'image_encoder.blocks.7.norm1.weight', 'image_encoder.blocks.7.norm1.bias', 'image_encoder.blocks.7.attn.rel_pos_h', 'image_encoder.blocks.7.attn.rel_pos_w', 'image_encoder.blocks.7.attn.qkv.weight', 'image_encoder.blocks.7.attn.qkv.bias', 'image_encoder.blocks.7.attn.proj.weight', 'image_encoder.blocks.7.attn.proj.bias', 'image_encoder.blocks.7.norm2.weight', 'image_encoder.blocks.7.norm2.bias', 'image_encoder.blocks.7.mlp.lin1.weight', 'image_encoder.blocks.7.mlp.lin1.bias', 'image_encoder.blocks.7.mlp.lin2.weight', 'image_encoder.blocks.7.mlp.lin2.bias', 'image_encoder.blocks.8.norm1.weight', 'image_encoder.blocks.8.norm1.bias', 'image_encoder.blocks.8.attn.rel_pos_h', 'image_encoder.blocks.8.attn.rel_pos_w', 'image_encoder.blocks.8.attn.qkv.weight', 'image_encoder.blocks.8.attn.qkv.bias', 'image_encoder.blocks.8.attn.proj.weight', 'image_encoder.blocks.8.attn.proj.bias', 'image_encoder.blocks.8.norm2.weight', 'image_encoder.blocks.8.norm2.bias', 'image_encoder.blocks.8.mlp.lin1.weight', 'image_encoder.blocks.8.mlp.lin1.bias', 'image_encoder.blocks.8.mlp.lin2.weight', 'image_encoder.blocks.8.mlp.lin2.bias', 'image_encoder.blocks.9.norm1.weight', 'image_encoder.blocks.9.norm1.bias', 'image_encoder.blocks.9.attn.rel_pos_h', 'image_encoder.blocks.9.attn.rel_pos_w', 'image_encoder.blocks.9.attn.qkv.weight', 'image_encoder.blocks.9.attn.qkv.bias', 'image_encoder.blocks.9.attn.proj.weight', 'image_encoder.blocks.9.attn.proj.bias', 'image_encoder.blocks.9.norm2.weight', 'image_encoder.blocks.9.norm2.bias', 'image_encoder.blocks.9.mlp.lin1.weight', 'image_encoder.blocks.9.mlp.lin1.bias', 'image_encoder.blocks.9.mlp.lin2.weight', 'image_encoder.blocks.9.mlp.lin2.bias', 'image_encoder.blocks.10.norm1.weight', 'image_encoder.blocks.10.norm1.bias', 'image_encoder.blocks.10.attn.rel_pos_h', 'image_encoder.blocks.10.attn.rel_pos_w', 'image_encoder.blocks.10.attn.qkv.weight', 'image_encoder.blocks.10.attn.qkv.bias', 'image_encoder.blocks.10.attn.proj.weight', 'image_encoder.blocks.10.attn.proj.bias', 'image_encoder.blocks.10.norm2.weight', 'image_encoder.blocks.10.norm2.bias', 'image_encoder.blocks.10.mlp.lin1.weight', 'image_encoder.blocks.10.mlp.lin1.bias', 'image_encoder.blocks.10.mlp.lin2.weight', 'image_encoder.blocks.10.mlp.lin2.bias', 'image_encoder.blocks.11.norm1.weight', 'image_encoder.blocks.11.norm1.bias', 'image_encoder.blocks.11.attn.rel_pos_h', 'image_encoder.blocks.11.attn.rel_pos_w', 'image_encoder.blocks.11.attn.qkv.weight', 'image_encoder.blocks.11.attn.qkv.bias', 'image_encoder.blocks.11.attn.proj.weight', 'image_encoder.blocks.11.attn.proj.bias', 'image_encoder.blocks.11.norm2.weight', 'image_encoder.blocks.11.norm2.bias', 'image_encoder.blocks.11.mlp.lin1.weight', 'image_encoder.blocks.11.mlp.lin1.bias', 'image_encoder.blocks.11.mlp.lin2.weight', 'image_encoder.blocks.11.mlp.lin2.bias', 'image_encoder.pos_embed']
['patient_035']
['patient_057', 'patient_028', 'patient_087', 'patient_061', 'patient_032', 'patient_011', 'patient_078', 'patient_009', 'patient_068', 'patient_021', 'patient_079', 'patient_004', 'patient_089', 'patient_023', 'patient_070']
['patient_014', 'patient_060', 'patient_044', 'patient_036', 'patient_003', 'patient_100', 'patient_065', 'patient_013', 'patient_038', 'patient_093', 'patient_043', 'patient_082', 'patient_031', 'patient_005', 'patient_016']
dataset length: 26
dataset length: 258
dataset length: 296
output_experiment/basic120
Train: [0][0/7]	loss 2.1807
VALIDATE
Epoch:  0 Loss: 0.9410
Train: [1][0/7]	loss 1.1899
VALIDATE
Epoch:  1 Loss: 0.9226
Train: [2][0/7]	loss 1.0460
VALIDATE
Epoch:  2 Loss: 0.8573
Train: [3][0/7]	loss 1.1838
VALIDATE
Epoch:  3 Loss: 0.8509
Train: [4][0/7]	loss 1.4463
VALIDATE
Epoch:  4 Loss: 0.7575
Train: [5][0/7]	loss 1.1197
VALIDATE
Epoch:  5 Loss: 0.7304
Train: [6][0/7]	loss 1.0496
VALIDATE
Epoch:  6 Loss: 0.7044
Train: [7][0/7]	loss 0.9219
VALIDATE
Epoch:  7 Loss: 0.6777
Train: [8][0/7]	loss 1.0469
VALIDATE
Epoch:  8 Loss: 0.6105
Train: [9][0/7]	loss 1.0448
VALIDATE
Epoch:  9 Loss: 0.6453
Train: [10][0/7]	loss 0.9425
VALIDATE
Epoch: 10 Loss: 0.5501
Train: [11][0/7]	loss 1.0965
VALIDATE
Epoch: 11 Loss: 0.5739
Train: [12][0/7]	loss 1.0487
VALIDATE
Epoch: 12 Loss: 0.6162
Train: [13][0/7]	loss 0.6908
VALIDATE
Epoch: 13 Loss: 0.5612
Train: [14][0/7]	loss 0.8850
VALIDATE
Epoch: 14 Loss: 0.5543
Train: [15][0/7]	loss 0.9282
VALIDATE
Epoch: 15 Loss: 0.5602
Train: [16][0/7]	loss 0.7558
VALIDATE
Epoch: 16 Loss: 0.5323
Train: [17][0/7]	loss 0.7892
VALIDATE
Epoch: 17 Loss: 0.4882
Train: [18][0/7]	loss 0.6096
VALIDATE
Epoch: 18 Loss: 0.5102
Train: [19][0/7]	loss 0.8065
VALIDATE
Epoch: 19 Loss: 0.4814
Train: [20][0/7]	loss 1.1524
VALIDATE
Epoch: 20 Loss: 0.4753
Train: [21][0/7]	loss 0.6128
VALIDATE
Epoch: 21 Loss: 0.4939
Train: [22][0/7]	loss 0.6077
VALIDATE
Epoch: 22 Loss: 0.4417
Train: [23][0/7]	loss 0.9959
VALIDATE
Epoch: 23 Loss: 0.4767
Train: [24][0/7]	loss 0.8810
VALIDATE
Epoch: 24 Loss: 0.5020
Train: [25][0/7]	loss 0.6231
VALIDATE
Epoch: 25 Loss: 0.4349
Train: [26][0/7]	loss 0.9919
VALIDATE
Epoch: 26 Loss: 0.4634
Train: [27][0/7]	loss 0.5211
VALIDATE
Epoch: 27 Loss: 0.4507
Train: [28][0/7]	loss 0.8667
VALIDATE
Epoch: 28 Loss: 0.4436
Train: [29][0/7]	loss 0.9410
VALIDATE
Epoch: 29 Loss: 0.4415
Train: [30][0/7]	loss 0.9881
VALIDATE
Epoch: 30 Loss: 0.3877
Train: [31][0/7]	loss 0.6102
VALIDATE
Epoch: 31 Loss: 0.3930
Train: [32][0/7]	loss 0.3701
VALIDATE
Epoch: 32 Loss: 0.3909
Train: [33][0/7]	loss 1.0322
VALIDATE
Epoch: 33 Loss: 0.4131
Train: [34][0/7]	loss 0.6503
VALIDATE
Epoch: 34 Loss: 0.3836
Train: [35][0/7]	loss 0.7713
VALIDATE
Epoch: 35 Loss: 0.3443
Train: [36][0/7]	loss 0.6150
VALIDATE
Epoch: 36 Loss: 0.3612
Train: [37][0/7]	loss 0.7676
VALIDATE
Epoch: 37 Loss: 0.3610
Train: [38][0/7]	loss 0.3948
VALIDATE
Epoch: 38 Loss: 0.3361
Train: [39][0/7]	loss 1.0798
VALIDATE
Epoch: 39 Loss: 0.3109
Train: [40][0/7]	loss 0.8152
VALIDATE
Epoch: 40 Loss: 0.3344
Train: [41][0/7]	loss 0.4085
VALIDATE
Epoch: 41 Loss: 0.3246
Train: [42][0/7]	loss 0.9696
VALIDATE
Epoch: 42 Loss: 0.2934
Train: [43][0/7]	loss 0.8096
VALIDATE
Epoch: 43 Loss: 0.4049
Train: [44][0/7]	loss 0.6150
VALIDATE
Epoch: 44 Loss: 0.4311
Train: [45][0/7]	loss 0.6044
VALIDATE
Epoch: 45 Loss: 0.3917
Train: [46][0/7]	loss 0.3553
VALIDATE
Epoch: 46 Loss: 0.4102
Train: [47][0/7]	loss 0.8080
VALIDATE
Epoch: 47 Loss: 0.3646
Train: [48][0/7]	loss 0.4867
VALIDATE
Epoch: 48 Loss: 0.2968
Train: [49][0/7]	loss 0.5666
VALIDATE
Epoch: 49 Loss: 0.2806
Train: [50][0/7]	loss 0.4873
VALIDATE
Epoch: 50 Loss: 0.2821
Train: [51][0/7]	loss 0.3991
VALIDATE
Epoch: 51 Loss: 0.2774
Train: [52][0/7]	loss 0.4428
VALIDATE
Epoch: 52 Loss: 0.2648
Train: [53][0/7]	loss 0.7040
VALIDATE
Epoch: 53 Loss: 0.2661
Train: [54][0/7]	loss 0.6859
VALIDATE
Epoch: 54 Loss: 0.2599
Train: [55][0/7]	loss 0.2495
VALIDATE
Epoch: 55 Loss: 0.2552
Train: [56][0/7]	loss 0.3359
VALIDATE
Epoch: 56 Loss: 0.2516
Train: [57][0/7]	loss 0.6445
VALIDATE
Epoch: 57 Loss: 0.2535
Train: [58][0/7]	loss 0.9199
VALIDATE
Epoch: 58 Loss: 0.2640
Train: [59][0/7]	loss 0.7357
VALIDATE
Epoch: 59 Loss: 0.2607
Train: [60][0/7]	loss 0.5027
VALIDATE
Epoch: 60 Loss: 0.2516
Train: [61][0/7]	loss 0.2014
VALIDATE
Epoch: 61 Loss: 0.2510
Train: [62][0/7]	loss 0.6790
VALIDATE
Epoch: 62 Loss: 0.2566
Train: [63][0/7]	loss 0.3760
VALIDATE
Epoch: 63 Loss: 0.2514
Train: [64][0/7]	loss 0.4430
VALIDATE
Epoch: 64 Loss: 0.2529
Train: [65][0/7]	loss 0.8765
VALIDATE
Epoch: 65 Loss: 0.2507
Train: [66][0/7]	loss 0.4844
VALIDATE
Epoch: 66 Loss: 0.2523
Train: [67][0/7]	loss 0.2829
VALIDATE
Epoch: 67 Loss: 0.2491
Train: [68][0/7]	loss 0.6161
VALIDATE
Epoch: 68 Loss: 0.2457
Train: [69][0/7]	loss 0.7631
VALIDATE
Epoch: 69 Loss: 0.2469
Train: [70][0/7]	loss 0.2687
VALIDATE
Epoch: 70 Loss: 0.2543
Train: [71][0/7]	loss 0.8325
VALIDATE
Epoch: 71 Loss: 0.2580
Train: [72][0/7]	loss 0.5990
VALIDATE
Epoch: 72 Loss: 0.2603
Train: [73][0/7]	loss 0.2698
VALIDATE
Epoch: 73 Loss: 0.2466
Train: [74][0/7]	loss 1.1373
VALIDATE
Epoch: 74 Loss: 0.2463
Train: [75][0/7]	loss 0.3149
VALIDATE
Epoch: 75 Loss: 0.2450
Train: [76][0/7]	loss 0.1754
VALIDATE
Epoch: 76 Loss: 0.2474
Train: [77][0/7]	loss 0.6834
VALIDATE
Epoch: 77 Loss: 0.2490
Train: [78][0/7]	loss 0.8159
VALIDATE
Epoch: 78 Loss: 0.2562
Train: [79][0/7]	loss 0.5249
VALIDATE
Epoch: 79 Loss: 0.2483
Train: [80][0/7]	loss 0.7036
VALIDATE
Epoch: 80 Loss: 0.2494
Train: [81][0/7]	loss 0.2739
VALIDATE
Epoch: 81 Loss: 0.2558
Train: [82][0/7]	loss 0.4521
VALIDATE
Epoch: 82 Loss: 0.2461
Train: [83][0/7]	loss 0.8152
VALIDATE
Epoch: 83 Loss: 0.2524
Train: [84][0/7]	loss 0.3337
VALIDATE
Epoch: 84 Loss: 0.2497
Train: [85][0/7]	loss 0.8059
VALIDATE
Epoch: 85 Loss: 0.2471
Train: [86][0/7]	loss 0.1656
VALIDATE
Epoch: 86 Loss: 0.2542
Train: [87][0/7]	loss 0.6806
VALIDATE
Epoch: 87 Loss: 0.2587
Train: [88][0/7]	loss 0.8585
VALIDATE
Epoch: 88 Loss: 0.2465
Train: [89][0/7]	loss 0.1870
VALIDATE
Epoch: 89 Loss: 0.2462
Train: [90][0/7]	loss 0.7600
VALIDATE
Epoch: 90 Loss: 0.2470
Train: [91][0/7]	loss 0.2949
VALIDATE
Epoch: 91 Loss: 0.2573
Train: [92][0/7]	loss 0.6589
VALIDATE
Epoch: 92 Loss: 0.2501
Train: [93][0/7]	loss 0.4283
VALIDATE
Epoch: 93 Loss: 0.2523
Train: [94][0/7]	loss 0.5337
VALIDATE
Epoch: 94 Loss: 0.2467
Train: [95][0/7]	loss 0.5859
VALIDATE
Epoch: 95 Loss: 0.2483
Train: [96][0/7]	loss 0.2802
VALIDATE
Epoch: 96 Loss: 0.2465
Train: [97][0/7]	loss 1.0283
VALIDATE
Epoch: 97 Loss: 0.2514
Train: [98][0/7]	loss 0.3177
VALIDATE
Epoch: 98 Loss: 0.2475
Train: [99][0/7]	loss 1.0046
VALIDATE
Epoch: 99 Loss: 0.2541
Train: [100][0/7]	loss 0.7641
VALIDATE
Epoch: 100 Loss: 0.2471
Train: [101][0/7]	loss 0.4213
VALIDATE
Epoch: 101 Loss: 0.2487
Train: [102][0/7]	loss 0.3579
VALIDATE
Epoch: 102 Loss: 0.2443
Train: [103][0/7]	loss 1.0468
VALIDATE
Epoch: 103 Loss: 0.2556
Train: [104][0/7]	loss 0.6233
VALIDATE
Epoch: 104 Loss: 0.2500
Train: [105][0/7]	loss 0.6014
VALIDATE
Epoch: 105 Loss: 0.2507
Train: [106][0/7]	loss 0.6247
VALIDATE
Epoch: 106 Loss: 0.2477
Train: [107][0/7]	loss 0.4547
VALIDATE
Epoch: 107 Loss: 0.2526
Train: [108][0/7]	loss 0.4582
VALIDATE
Epoch: 108 Loss: 0.2531
Train: [109][0/7]	loss 0.2407
VALIDATE
Epoch: 109 Loss: 0.2494
Train: [110][0/7]	loss 0.2172
VALIDATE
Epoch: 110 Loss: 0.2505
Train: [111][0/7]	loss 0.2216
VALIDATE
Epoch: 111 Loss: 0.2503
Train: [112][0/7]	loss 0.2360
VALIDATE
Epoch: 112 Loss: 0.2517
Train: [113][0/7]	loss 0.9007
VALIDATE
Epoch: 113 Loss: 0.2491
Train: [114][0/7]	loss 0.5075
VALIDATE
Epoch: 114 Loss: 0.2603
Train: [115][0/7]	loss 0.5560
VALIDATE
Epoch: 115 Loss: 0.2428
Train: [116][0/7]	loss 0.3492
VALIDATE
Epoch: 116 Loss: 0.2533
Train: [117][0/7]	loss 0.8842
VALIDATE
Epoch: 117 Loss: 0.2467
Train: [118][0/7]	loss 0.3226
VALIDATE
Epoch: 118 Loss: 0.2502
Train: [119][0/7]	loss 0.9221
VALIDATE
Epoch: 119 Loss: 0.2475
Test
dataset length: 20
(20, 224, 224) (20, 224, 224)
finish saving file: patient_014
dataset length: 18
(18, 224, 224) (18, 224, 224)
finish saving file: patient_060
dataset length: 18
(18, 224, 224) (18, 224, 224)
finish saving file: patient_044
dataset length: 16
(16, 224, 224) (16, 224, 224)
finish saving file: patient_036
dataset length: 20
(20, 224, 224) (20, 224, 224)
finish saving file: patient_003
dataset length: 16
(16, 224, 224) (16, 224, 224)
finish saving file: patient_100
dataset length: 16
(16, 224, 224) (16, 224, 224)
finish saving file: patient_065
dataset length: 20
(20, 224, 224) (20, 224, 224)
finish saving file: patient_013
dataset length: 16
(16, 224, 224) (16, 224, 224)
finish saving file: patient_038
dataset length: 20
(20, 224, 224) (20, 224, 224)
finish saving file: patient_093
dataset length: 24
(24, 224, 224) (24, 224, 224)
finish saving file: patient_043
dataset length: 32
(32, 224, 224) (32, 224, 224)
finish saving file: patient_082
dataset length: 20
(20, 224, 224) (20, 224, 224)
finish saving file: patient_031
dataset length: 20
(20, 224, 224) (20, 224, 224)
finish saving file: patient_005
dataset length: 20
/home/kl321/miniconda3/envs/medsam/lib/python3.10/site-packages/medpy/metric/binary.py:1200: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.
  result = numpy.atleast_1d(result.astype(numpy.bool))
(20, 224, 224) (20, 224, 224)
finish saving file: patient_016
patient_003.nii
patient_003.nii
Traceback (most recent call last):
  File "/home/kl321/AutoSAM/scripts/main_feat_seg.py", line 473, in <module>
    main()
  File "/home/kl321/AutoSAM/scripts/main_feat_seg.py", line 133, in main
    main_worker(args.gpu, ngpus_per_node, args)
  File "/home/kl321/AutoSAM/scripts/main_feat_seg.py", line 267, in main_worker
    test_acdc(args)
  File "/home/kl321/AutoSAM/evaluate.py", line 141, in test_acdc
    # hd_rv.append(hd(infer_rv, label_rv))
  File "/home/kl321/AutoSAM/evaluate.py", line 25, in hd
    hd95 = metric.binary.hd95(pred, gt)
  File "/home/kl321/miniconda3/envs/medsam/lib/python3.10/site-packages/medpy/metric/binary.py", line 396, in hd95
    hd1 = __surface_distances(result, reference, voxelspacing, connectivity)
  File "/home/kl321/miniconda3/envs/medsam/lib/python3.10/site-packages/medpy/metric/binary.py", line 1200, in __surface_distances
    result = numpy.atleast_1d(result.astype(numpy.bool))
  File "/home/kl321/miniconda3/envs/medsam/lib/python3.10/site-packages/numpy/__init__.py", line 324, in __getattr__
    raise AttributeError(__former_attrs__[attr])
AttributeError: module 'numpy' has no attribute 'bool'.
`np.bool` was a deprecated alias for the builtin `bool`. To avoid this error in existing code, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:
    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations. Did you mean: 'bool_'?
